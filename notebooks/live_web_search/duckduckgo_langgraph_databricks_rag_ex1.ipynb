{
 "cells": [
  {
      "cell_type": "markdown",
      "id": "6a44f009",
      "metadata": {
        "id": "6a44f009"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimitarpg13/agentic_architectures_and_design_patterns/blob/main/notebooks/live_web_search/duckduckgo_langgraph_databricks_rag_ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with Databricks Vector Search, DuckDuckGo, and LangGraph\n",
    "\n",
    "This notebook demonstrates a production-ready RAG system that combines:\n",
    "- **Databricks Vector Search**: Enterprise-grade vector database\n",
    "- **DuckDuckGo**: Live web search for current information\n",
    "- **LangGraph**: Intelligent workflow orchestration\n",
    "- **Unity Catalog**: Data governance and management\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "User Query ‚Üí Router Agent\n",
    "                ‚Üì\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚Üì                       ‚Üì\n",
    "Databricks Vector      DuckDuckGo\n",
    "   Search                Web Search\n",
    "    ‚Üì                       ‚Üì\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                ‚Üì\n",
    "        Context Synthesis\n",
    "                ‚Üì\n",
    "          LLM Generation\n",
    "                ‚Üì\n",
    "          Final Answer\n",
    "```\n",
    "\n",
    "## Features\n",
    "- üè¢ Enterprise-grade vector search with Databricks\n",
    "- üîç Hybrid retrieval (vector DB + web search)\n",
    "- üîÑ Intelligent routing with LangGraph\n",
    "- üìä Unity Catalog integration\n",
    "- ‚ö° High-performance Delta Lake storage\n",
    "- üîê Built-in security and governance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q databricks-vectorsearch databricks-sdk langchain langchain-openai \\\n",
    "    langgraph langchain-community duckduckgo-search mlflow pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, List, Dict, Any, Optional\n",
    "import operator\n",
    "import json\n",
    "\n",
    "# Databricks imports\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.catalog import *\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Other imports\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Databricks Connection\n",
    "\n",
    "### Authentication Options:\n",
    "1. **Databricks Notebook**: Automatically authenticated\n",
    "2. **Local/External**: Use personal access token\n",
    "3. **Service Principal**: For production deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks Configuration\n",
    "# Option 1: Running in Databricks notebook (auto-authenticated)\n",
    "# No configuration needed - credentials are automatically available\n",
    "\n",
    "# Option 2: Running locally or outside Databricks\n",
    "DATABRICKS_HOST = \"https://your-workspace.cloud.databricks.com\"  # Your workspace URL\n",
    "DATABRICKS_TOKEN = \"your-personal-access-token\"  # Your PAT\n",
    "\n",
    "# Set environment variables for local development\n",
    "os.environ[\"DATABRICKS_HOST\"] = DATABRICKS_HOST\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = DATABRICKS_TOKEN\n",
    "\n",
    "# OpenAI Configuration\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"\n",
    "\n",
    "print(\"‚úÖ Configuration set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set Up Unity Catalog Resources\n",
    "\n",
    "Define the catalog, schema, and table names for organizing your vector data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unity Catalog Configuration\n",
    "CATALOG_NAME = \"main\"  # Or your custom catalog\n",
    "SCHEMA_NAME = \"rag_demo\"  # Schema for RAG application\n",
    "TABLE_NAME = \"knowledge_base\"  # Delta table for documents\n",
    "VECTOR_SEARCH_ENDPOINT = \"rag_endpoint\"  # Vector Search endpoint name\n",
    "INDEX_NAME = \"knowledge_base_index\"  # Vector search index name\n",
    "\n",
    "# Full qualified names\n",
    "FULL_TABLE_NAME = f\"{CATALOG_NAME}.{SCHEMA_NAME}.{TABLE_NAME}\"\n",
    "FULL_INDEX_NAME = f\"{CATALOG_NAME}.{SCHEMA_NAME}.{INDEX_NAME}\"\n",
    "\n",
    "print(f\"üìä Catalog: {CATALOG_NAME}\")\n",
    "print(f\"üìÅ Schema: {SCHEMA_NAME}\")\n",
    "print(f\"üìÑ Table: {FULL_TABLE_NAME}\")\n",
    "print(f\"üîç Index: {FULL_INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Databricks Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Databricks clients\n",
    "try:\n",
    "    # Workspace client for catalog operations\n",
    "    workspace_client = WorkspaceClient()\n",
    "    \n",
    "    # Vector Search client\n",
    "    vector_search_client = VectorSearchClient(\n",
    "        workspace_url=DATABRICKS_HOST,\n",
    "        personal_access_token=DATABRICKS_TOKEN,\n",
    "        disable_notice=True\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Databricks clients initialized successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing clients: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Verify DATABRICKS_HOST and DATABRICKS_TOKEN are set correctly\")\n",
    "    print(\"2. Ensure your PAT has the necessary permissions\")\n",
    "    print(\"3. Check network connectivity to Databricks workspace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Unity Catalog Schema (if not exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This would typically run on Databricks using Spark SQL\n",
    "# Here's the SQL command to run in Databricks:\n",
    "\n",
    "create_schema_sql = f\"\"\"\n",
    "-- Create catalog if not exists\n",
    "CREATE CATALOG IF NOT EXISTS {CATALOG_NAME};\n",
    "\n",
    "-- Create schema if not exists\n",
    "CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}\n",
    "COMMENT 'Schema for RAG application with vector search';\n",
    "\"\"\"\n",
    "\n",
    "print(\"SQL to run in Databricks SQL Editor or notebook:\")\n",
    "print(create_schema_sql)\n",
    "print(\"\\n‚ö†Ô∏è  Run the above SQL in your Databricks workspace before proceeding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Sample Documents Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents for the knowledge base\n",
    "sample_documents = [\n",
    "    {\n",
    "        \"id\": \"doc_001\",\n",
    "        \"content\": \"\"\"Databricks is a unified data analytics platform built on Apache Spark. \n",
    "        It provides collaborative notebooks, automated cluster management, and production-grade \n",
    "        data pipelines. Databricks simplifies big data processing and machine learning workflows.\"\"\",\n",
    "        \"title\": \"Introduction to Databricks\",\n",
    "        \"category\": \"platform\",\n",
    "        \"source\": \"databricks_docs\",\n",
    "        \"date\": \"2024-01-15\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_002\",\n",
    "        \"content\": \"\"\"Unity Catalog is Databricks' unified governance solution for data and AI. \n",
    "        It provides centralized access control, auditing, lineage, and data discovery across \n",
    "        Databricks workspaces. Unity Catalog works with Delta Lake to provide fine-grained \n",
    "        governance for tables, views, and models.\"\"\",\n",
    "        \"title\": \"Unity Catalog Overview\",\n",
    "        \"category\": \"governance\",\n",
    "        \"source\": \"unity_catalog_guide\",\n",
    "        \"date\": \"2024-01-20\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_003\",\n",
    "        \"content\": \"\"\"Databricks Vector Search is a serverless vector database that makes it easy to \n",
    "        build retrieval-augmented generation (RAG) applications. It automatically indexes and \n",
    "        syncs embeddings from Delta tables, provides high-performance similarity search, and \n",
    "        integrates seamlessly with Unity Catalog for governance.\"\"\",\n",
    "        \"title\": \"Databricks Vector Search\",\n",
    "        \"category\": \"vector_search\",\n",
    "        \"source\": \"vector_search_docs\",\n",
    "        \"date\": \"2024-02-01\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_004\",\n",
    "        \"content\": \"\"\"Delta Lake is an open-source storage layer that brings ACID transactions to \n",
    "        Apache Spark and big data workloads. It provides time travel, schema enforcement, and \n",
    "        unified batch and streaming processing. Delta Lake is the foundation for the lakehouse \n",
    "        architecture.\"\"\",\n",
    "        \"title\": \"Delta Lake Fundamentals\",\n",
    "        \"category\": \"storage\",\n",
    "        \"source\": \"delta_lake_guide\",\n",
    "        \"date\": \"2024-01-10\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_005\",\n",
    "        \"content\": \"\"\"MLflow is an open-source platform for managing the machine learning lifecycle. \n",
    "        It includes experiment tracking, model registry, and model deployment capabilities. \n",
    "        MLflow integrates with Databricks to provide a complete MLOps solution.\"\"\",\n",
    "        \"title\": \"MLflow Platform\",\n",
    "        \"category\": \"mlops\",\n",
    "        \"source\": \"mlflow_docs\",\n",
    "        \"date\": \"2024-01-25\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_006\",\n",
    "        \"content\": \"\"\"LangChain is a framework for developing applications powered by language models. \n",
    "        It provides abstractions for prompts, chains, agents, and memory. LangChain works \n",
    "        seamlessly with Databricks for building production RAG applications.\"\"\",\n",
    "        \"title\": \"LangChain Framework\",\n",
    "        \"category\": \"frameworks\",\n",
    "        \"source\": \"langchain_guide\",\n",
    "        \"date\": \"2024-02-05\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_007\",\n",
    "        \"content\": \"\"\"Our company policy on data governance: All production data must be stored in \n",
    "        Unity Catalog with appropriate access controls. Data classification should follow \n",
    "        the company's data classification standard. PII data requires encryption at rest \n",
    "        and column-level access controls.\"\"\",\n",
    "        \"title\": \"Data Governance Policy\",\n",
    "        \"category\": \"policy\",\n",
    "        \"source\": \"company_handbook\",\n",
    "        \"date\": \"2024-01-01\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "docs_df = pd.DataFrame(sample_documents)\n",
    "\n",
    "print(f\"‚úÖ Created {len(sample_documents)} sample documents\")\n",
    "print(\"\\nSample data:\")\n",
    "print(docs_df[['id', 'title', 'category']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Initialize Embeddings Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI embeddings\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=1536  # Standard dimension for text-embedding-3-small\n",
    ")\n",
    "\n",
    "# Test embeddings\n",
    "test_text = \"This is a test document.\"\n",
    "test_embedding = embeddings_model.embed_query(test_text)\n",
    "\n",
    "print(f\"‚úÖ Embeddings model initialized\")\n",
    "print(f\"üìä Embedding dimension: {len(test_embedding)}\")\n",
    "print(f\"üî¢ Sample embedding (first 5 values): {test_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Embeddings for Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all documents\n",
    "print(\"üîÑ Generating embeddings for documents...\")\n",
    "\n",
    "embeddings_list = []\n",
    "for doc in sample_documents:\n",
    "    # Combine title and content for better embeddings\n",
    "    text_to_embed = f\"{doc['title']}: {doc['content']}\"\n",
    "    embedding = embeddings_model.embed_query(text_to_embed)\n",
    "    embeddings_list.append(embedding)\n",
    "    print(f\"  ‚úì Embedded: {doc['id']}\")\n",
    "\n",
    "# Add embeddings to dataframe\n",
    "docs_df['embedding'] = embeddings_list\n",
    "\n",
    "print(f\"\\n‚úÖ Generated {len(embeddings_list)} embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Delta Table with Documents\n",
    "\n",
    "**Note**: This section shows the SQL commands to run in Databricks.\n",
    "In a real Databricks notebook, you would use Spark DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL to create the Delta table in Databricks\n",
    "create_table_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {FULL_TABLE_NAME} (\n",
    "  id STRING,\n",
    "  content STRING,\n",
    "  title STRING,\n",
    "  category STRING,\n",
    "  source STRING,\n",
    "  date STRING,\n",
    "  embedding ARRAY<FLOAT>,\n",
    "  created_at TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "COMMENT 'Knowledge base for RAG application';\n",
    "\"\"\"\n",
    "\n",
    "print(\"SQL to create Delta table:\")\n",
    "print(create_table_sql)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# In a Databricks notebook with Spark, you would do:\n",
    "spark_save_code = f\"\"\"\n",
    "# Convert pandas DataFrame to Spark DataFrame\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "spark_df = spark.createDataFrame(docs_df)\n",
    "spark_df = spark_df.withColumn(\"created_at\", current_timestamp())\n",
    "\n",
    "# Write to Delta table\n",
    "spark_df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"{FULL_TABLE_NAME}\")\n",
    "\n",
    "print(f\"‚úÖ Saved {{len(docs_df)}} documents to {{FULL_TABLE_NAME}}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nPython code to run in Databricks Spark notebook:\")\n",
    "print(spark_save_code)\n",
    "print(\"\\n‚ö†Ô∏è  Run the above code in your Databricks notebook to create and populate the table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Create Vector Search Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_search_endpoint(endpoint_name: str):\n",
    "    \"\"\"\n",
    "    Create a Vector Search endpoint if it doesn't exist.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if endpoint already exists\n",
    "        try:\n",
    "            endpoint = vector_search_client.get_endpoint(endpoint_name)\n",
    "            print(f\"‚úÖ Endpoint '{endpoint_name}' already exists\")\n",
    "            return endpoint\n",
    "        except Exception:\n",
    "            # Endpoint doesn't exist, create it\n",
    "            print(f\"üîÑ Creating endpoint '{endpoint_name}'...\")\n",
    "            \n",
    "            endpoint = vector_search_client.create_endpoint(\n",
    "                name=endpoint_name,\n",
    "                endpoint_type=\"STANDARD\"  # or \"HIGH_CONCURRENCY\" for production\n",
    "            )\n",
    "            \n",
    "            print(f\"‚úÖ Created endpoint '{endpoint_name}'\")\n",
    "            print(f\"‚è≥ Endpoint is initializing (this may take a few minutes)...\")\n",
    "            \n",
    "            return endpoint\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating endpoint: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create endpoint\n",
    "endpoint = create_vector_search_endpoint(VECTOR_SEARCH_ENDPOINT)\n",
    "\n",
    "if endpoint:\n",
    "    print(f\"\\nüìç Endpoint Name: {VECTOR_SEARCH_ENDPOINT}\")\n",
    "    print(f\"üìä Endpoint Status: Check in Databricks UI under Compute > Vector Search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Create Vector Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_search_index(\n",
    "    endpoint_name: str,\n",
    "    index_name: str,\n",
    "    table_name: str,\n",
    "    embedding_dimension: int = 1536\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a Vector Search index on the Delta table.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if index already exists\n",
    "        try:\n",
    "            index = vector_search_client.get_index(endpoint_name, index_name)\n",
    "            print(f\"‚úÖ Index '{index_name}' already exists\")\n",
    "            return index\n",
    "        except Exception:\n",
    "            # Index doesn't exist, create it\n",
    "            print(f\"üîÑ Creating index '{index_name}'...\")\n",
    "            \n",
    "            index = vector_search_client.create_delta_sync_index(\n",
    "                endpoint_name=endpoint_name,\n",
    "                index_name=index_name,\n",
    "                source_table_name=table_name,\n",
    "                pipeline_type=\"TRIGGERED\",  # or \"CONTINUOUS\" for real-time sync\n",
    "                primary_key=\"id\",\n",
    "                embedding_dimension=embedding_dimension,\n",
    "                embedding_vector_column=\"embedding\"\n",
    "            )\n",
    "            \n",
    "            print(f\"‚úÖ Created index '{index_name}'\")\n",
    "            print(f\"‚è≥ Index is being built (this may take several minutes)...\")\n",
    "            print(f\"üìä Monitor progress in Databricks UI\")\n",
    "            \n",
    "            return index\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating index: {e}\")\n",
    "        print(\"\\nCommon issues:\")\n",
    "        print(\"1. Endpoint not ready - wait for endpoint to be ONLINE\")\n",
    "        print(\"2. Table doesn't exist - create the Delta table first\")\n",
    "        print(\"3. Permission issues - ensure you have CREATE privilege\")\n",
    "        return None\n",
    "\n",
    "# Create index\n",
    "index = create_vector_search_index(\n",
    "    endpoint_name=VECTOR_SEARCH_ENDPOINT,\n",
    "    index_name=FULL_INDEX_NAME,\n",
    "    table_name=FULL_TABLE_NAME,\n",
    "    embedding_dimension=1536\n",
    ")\n",
    "\n",
    "if index:\n",
    "    print(f\"\\nüîç Index Name: {FULL_INDEX_NAME}\")\n",
    "    print(f\"üìä Source Table: {FULL_TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Test Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vector_search(query: str, k: int = 3):\n",
    "    \"\"\"\n",
    "    Test vector search with a query.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç Searching for: '{query}'\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Generate query embedding\n",
    "        query_embedding = embeddings_model.embed_query(query)\n",
    "        \n",
    "        # Search the index\n",
    "        results = vector_search_client.get_index(\n",
    "            endpoint_name=VECTOR_SEARCH_ENDPOINT,\n",
    "            index_name=FULL_INDEX_NAME\n",
    "        ).similarity_search(\n",
    "            query_vector=query_embedding,\n",
    "            columns=[\"id\", \"title\", \"content\", \"category\", \"source\"],\n",
    "            num_results=k\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Found {len(results.get('result', {}).get('data_array', []))} results\\n\")\n",
    "        \n",
    "        # Display results\n",
    "        for i, result in enumerate(results.get('result', {}).get('data_array', []), 1):\n",
    "            print(f\"Result {i}:\")\n",
    "            print(f\"  ID: {result[0]}\")\n",
    "            print(f\"  Title: {result[1]}\")\n",
    "            print(f\"  Content: {result[2][:100]}...\")\n",
    "            print(f\"  Category: {result[3]}\")\n",
    "            print(f\"  Score: {result[-1] if len(result) > 5 else 'N/A'}\")\n",
    "            print()\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error searching: {e}\")\n",
    "        print(\"\\nPossible issues:\")\n",
    "        print(\"1. Index not ready - wait for indexing to complete\")\n",
    "        print(\"2. No data in table - ensure documents were loaded\")\n",
    "        print(\"3. Endpoint offline - check endpoint status\")\n",
    "        return None\n",
    "\n",
    "# Test search\n",
    "test_results = test_vector_search(\"What is Unity Catalog?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Initialize DuckDuckGo Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DuckDuckGo search\n",
    "web_search = DuckDuckGoSearchResults(\n",
    "    num_results=3,\n",
    "    output_format=\"list\"\n",
    ")\n",
    "\n",
    "# Test web search\n",
    "test_search = web_search.run(\"latest databricks features 2024\")\n",
    "print(\"‚úÖ DuckDuckGo search initialized\")\n",
    "print(f\"Test search returned results: {len(test_search) if isinstance(test_search, list) else 'Yes'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Define RAG State for LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabricksRAGState(TypedDict):\n",
    "    \"\"\"\n",
    "    State for the Databricks RAG workflow.\n",
    "    \"\"\"\n",
    "    # Input\n",
    "    query: str\n",
    "    \n",
    "    # Routing\n",
    "    use_vector_search: bool\n",
    "    use_web_search: bool\n",
    "    \n",
    "    # Retrieval results\n",
    "    vector_results: List[Dict[str, Any]]\n",
    "    web_results: List[Dict[str, Any]]\n",
    "    \n",
    "    # Processing\n",
    "    combined_context: str\n",
    "    sources: List[str]\n",
    "    \n",
    "    # Output\n",
    "    answer: str\n",
    "    confidence: float\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "print(\"‚úÖ RAG state defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Create Router Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "def route_query(state: DatabricksRAGState) -> DatabricksRAGState:\n",
    "    \"\"\"\n",
    "    Route query to appropriate retrieval sources.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üîÄ ROUTER NODE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    router_prompt = f\"\"\"Analyze this query and determine the best retrieval strategy:\n",
    "\n",
    "Query: \"{query}\"\n",
    "\n",
    "Available sources:\n",
    "1. Databricks Vector Search: Internal knowledge base about Databricks, Unity Catalog, \n",
    "   Delta Lake, MLflow, data governance, and company policies\n",
    "2. Web Search: Current news, latest features, recent announcements, and real-time information\n",
    "\n",
    "Decide:\n",
    "- use_vector_search: True if query is about internal documentation or company knowledge\n",
    "- use_web_search: True if query requires current/recent external information\n",
    "\n",
    "Both can be True for queries needing both internal and external context.\n",
    "\n",
    "Examples:\n",
    "- \"What is Unity Catalog?\" ‚Üí vector: True, web: False\n",
    "- \"Latest Databricks announcements 2024\" ‚Üí vector: False, web: True\n",
    "- \"Compare Databricks Vector Search to Pinecone\" ‚Üí vector: True, web: True\n",
    "\n",
    "Respond with ONLY JSON: {{\"use_vector_search\": bool, \"use_web_search\": bool}}\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=router_prompt)])\n",
    "    \n",
    "    try:\n",
    "        decision = json.loads(response.content)\n",
    "        use_vector = decision.get(\"use_vector_search\", True)\n",
    "        use_web = decision.get(\"use_web_search\", False)\n",
    "    except:\n",
    "        use_vector = True\n",
    "        use_web = False\n",
    "    \n",
    "    print(f\"üìä Routing Decision:\")\n",
    "    print(f\"   Databricks Vector Search: {use_vector}\")\n",
    "    print(f\"   DuckDuckGo Web Search: {use_web}\")\n",
    "    \n",
    "    return {\n",
    "        \"use_vector_search\": use_vector,\n",
    "        \"use_web_search\": use_web\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Router node created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Create Databricks Vector Search Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_databricks_vectors(state: DatabricksRAGState) -> DatabricksRAGState:\n",
    "    \"\"\"\n",
    "    Search Databricks Vector Search index.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üîç DATABRICKS VECTOR SEARCH NODE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not state.get(\"use_vector_search\", False):\n",
    "        print(\"‚è≠Ô∏è  Skipping vector search\")\n",
    "        return {\"vector_results\": []}\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    try:\n",
    "        # Generate query embedding\n",
    "        print(f\"üîÑ Generating query embedding...\")\n",
    "        query_embedding = embeddings_model.embed_query(query)\n",
    "        \n",
    "        # Search the index\n",
    "        print(f\"üîé Searching Databricks Vector Search index...\")\n",
    "        results = vector_search_client.get_index(\n",
    "            endpoint_name=VECTOR_SEARCH_ENDPOINT,\n",
    "            index_name=FULL_INDEX_NAME\n",
    "        ).similarity_search(\n",
    "            query_vector=query_embedding,\n",
    "            columns=[\"id\", \"title\", \"content\", \"category\", \"source\"],\n",
    "            num_results=3\n",
    "        )\n",
    "        \n",
    "        # Parse results\n",
    "        vector_results = []\n",
    "        data_array = results.get('result', {}).get('data_array', [])\n",
    "        \n",
    "        for result in data_array:\n",
    "            vector_results.append({\n",
    "                \"id\": result[0],\n",
    "                \"title\": result[1],\n",
    "                \"content\": result[2],\n",
    "                \"category\": result[3],\n",
    "                \"source\": result[4],\n",
    "                \"score\": result[-1] if len(result) > 5 else None\n",
    "            })\n",
    "        \n",
    "        print(f\"‚úÖ Found {len(vector_results)} results from Databricks Vector Search\")\n",
    "        for i, result in enumerate(vector_results, 1):\n",
    "            print(f\"   {i}. {result['title']} (category: {result['category']})\")\n",
    "        \n",
    "        return {\"vector_results\": vector_results}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error searching vectors: {e}\")\n",
    "        return {\"vector_results\": []}\n",
    "\n",
    "print(\"‚úÖ Databricks vector search node created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Create Web Search Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_web(state: DatabricksRAGState) -> DatabricksRAGState:\n",
    "    \"\"\"\n",
    "    Search the web using DuckDuckGo.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üåê WEB SEARCH NODE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not state.get(\"use_web_search\", False):\n",
    "        print(\"‚è≠Ô∏è  Skipping web search\")\n",
    "        return {\"web_results\": []}\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    try:\n",
    "        print(f\"üîé Searching DuckDuckGo for: {query}\")\n",
    "        raw_results = web_search.run(query)\n",
    "        \n",
    "        # Parse results\n",
    "        web_results = []\n",
    "        if isinstance(raw_results, str):\n",
    "            snippets = raw_results.split('snippet: ')\n",
    "            for snippet in snippets[1:]:\n",
    "                parts = snippet.split('title: ')\n",
    "                if len(parts) > 1:\n",
    "                    title = parts[1].split('link: ')[0].strip()\n",
    "                    link = parts[1].split('link: ')[1].strip() if 'link: ' in parts[1] else \"\"\n",
    "                    web_results.append({\n",
    "                        \"title\": title,\n",
    "                        \"snippet\": parts[0].strip(),\n",
    "                        \"url\": link\n",
    "                    })\n",
    "        else:\n",
    "            web_results = raw_results if isinstance(raw_results, list) else []\n",
    "        \n",
    "        print(f\"‚úÖ Found {len(web_results)} web results\")\n",
    "        for i, result in enumerate(web_results[:3], 1):\n",
    "            print(f\"   {i}. {result.get('title', 'N/A')[:60]}...\")\n",
    "        \n",
    "        return {\"web_results\": web_results}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error searching web: {e}\")\n",
    "        return {\"web_results\": []}\n",
    "\n",
    "print(\"‚úÖ Web search node created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Create Context Builder Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(state: DatabricksRAGState) -> DatabricksRAGState:\n",
    "    \"\"\"\n",
    "    Combine results from Databricks and web search.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üî® CONTEXT BUILDER NODE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    context_parts = []\n",
    "    sources = []\n",
    "    \n",
    "    # Add Databricks Vector Search results\n",
    "    vector_results = state.get(\"vector_results\", [])\n",
    "    if vector_results:\n",
    "        context_parts.append(\"=== DATABRICKS KNOWLEDGE BASE ===\")\n",
    "        for i, result in enumerate(vector_results, 1):\n",
    "            context_parts.append(f\"\\n[Document {i}]\")\n",
    "            context_parts.append(f\"Title: {result['title']}\")\n",
    "            context_parts.append(f\"Content: {result['content']}\")\n",
    "            context_parts.append(f\"Category: {result['category']}\")\n",
    "            sources.append(f\"Databricks: {result['source']} ({result['id']})\")\n",
    "        print(f\"üìä Added {len(vector_results)} documents from Databricks\")\n",
    "    \n",
    "    # Add web search results\n",
    "    web_results = state.get(\"web_results\", [])\n",
    "    if web_results:\n",
    "        context_parts.append(\"\\n\\n=== WEB SEARCH RESULTS ===\")\n",
    "        for i, result in enumerate(web_results, 1):\n",
    "            context_parts.append(f\"\\n[Web Result {i}]\")\n",
    "            context_parts.append(f\"Title: {result.get('title', 'N/A')}\")\n",
    "            context_parts.append(f\"Content: {result.get('snippet', 'N/A')}\")\n",
    "            url = result.get('url', '')\n",
    "            if url:\n",
    "                sources.append(f\"Web: {url}\")\n",
    "        print(f\"üåê Added {len(web_results)} web search results\")\n",
    "    \n",
    "    combined_context = \"\\n\".join(context_parts)\n",
    "    \n",
    "    if not combined_context.strip():\n",
    "        combined_context = \"No relevant context found.\"\n",
    "    \n",
    "    print(f\"\\n‚úÖ Built context: {len(combined_context)} characters\")\n",
    "    print(f\"üìö Total sources: {len(sources)}\")\n",
    "    \n",
    "    return {\n",
    "        \"combined_context\": combined_context,\n",
    "        \"sources\": sources\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Context builder node created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Create Answer Generator Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: DatabricksRAGState) -> DatabricksRAGState:\n",
    "    \"\"\"\n",
    "    Generate final answer using LLM.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚ú® ANSWER GENERATOR NODE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    context = state.get(\"combined_context\", \"\")\n",
    "    sources = state.get(\"sources\", [])\n",
    "    \n",
    "    generation_prompt = f\"\"\"You are a helpful AI assistant with access to both internal \n",
    "Databricks documentation and live web search results.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Instructions:\n",
    "1. Answer the question based on the provided context\n",
    "2. Distinguish between Databricks knowledge base and web search results\n",
    "3. If information comes from Databricks docs, emphasize it's from internal knowledge\n",
    "4. If information comes from web search, note it's from external sources\n",
    "5. Be specific and cite which sources you're using\n",
    "6. If context is insufficient, acknowledge the limitation\n",
    "7. Provide a confidence score (0-1) based on source quality and relevance\n",
    "\n",
    "Format your response as:\n",
    "Answer: [your detailed answer]\n",
    "Confidence: [0.0-1.0]\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=generation_prompt)])\n",
    "        answer_text = response.content\n",
    "        \n",
    "        # Extract confidence if present\n",
    "        confidence = 0.8  # Default\n",
    "        if \"Confidence:\" in answer_text:\n",
    "            try:\n",
    "                conf_str = answer_text.split(\"Confidence:\")[1].split()[0]\n",
    "                confidence = float(conf_str)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print(f\"‚úÖ Generated answer ({len(answer_text)} characters)\")\n",
    "        print(f\"üìä Confidence: {confidence:.2f}\")\n",
    "        \n",
    "        metadata = {\n",
    "            \"vector_results_count\": len(state.get(\"vector_results\", [])),\n",
    "            \"web_results_count\": len(state.get(\"web_results\", [])),\n",
    "            \"total_sources\": len(sources),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \"answer\": answer_text,\n",
    "            \"confidence\": confidence,\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating answer: {e}\")\n",
    "        return {\n",
    "            \"answer\": \"I encountered an error generating the answer.\",\n",
    "            \"confidence\": 0.0,\n",
    "            \"metadata\": {}\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Answer generator node created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. Build the LangGraph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the workflow\n",
    "workflow = StateGraph(DatabricksRAGState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"route\", route_query)\n",
    "workflow.add_node(\"search_databricks\", search_databricks_vectors)\n",
    "workflow.add_node(\"search_web\", search_web)\n",
    "workflow.add_node(\"build_context\", build_context)\n",
    "workflow.add_node(\"generate\", generate_answer)\n",
    "\n",
    "# Define flow\n",
    "workflow.set_entry_point(\"route\")\n",
    "\n",
    "# Parallel retrieval\n",
    "workflow.add_edge(\"route\", \"search_databricks\")\n",
    "workflow.add_edge(\"route\", \"search_web\")\n",
    "\n",
    "# Both feed into context builder\n",
    "workflow.add_edge(\"search_databricks\", \"build_context\")\n",
    "workflow.add_edge(\"search_web\", \"build_context\")\n",
    "\n",
    "# Context builder to generator\n",
    "workflow.add_edge(\"build_context\", \"generate\")\n",
    "\n",
    "# Generator is the end\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile\n",
    "databricks_rag_app = workflow.compile()\n",
    "\n",
    "print(\"\\n‚úÖ Databricks RAG Application Ready!\")\n",
    "print(\"\\nüìä Workflow: Route ‚Üí [Databricks Vector Search + Web Search] ‚Üí Context ‚Üí Generate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. Helper Function to Query RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_databricks_rag(query: str, verbose: bool = True) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Query the Databricks RAG system.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ü§ñ DATABRICKS RAG SYSTEM\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\n‚ùì Query: {query}\\n\")\n",
    "    \n",
    "    # Initialize state\n",
    "    initial_state = {\n",
    "        \"query\": query,\n",
    "        \"use_vector_search\": False,\n",
    "        \"use_web_search\": False,\n",
    "        \"vector_results\": [],\n",
    "        \"web_results\": [],\n",
    "        \"combined_context\": \"\",\n",
    "        \"sources\": [],\n",
    "        \"answer\": \"\",\n",
    "        \"confidence\": 0.0,\n",
    "        \"metadata\": {}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Run workflow\n",
    "        final_state = databricks_rag_app.invoke(initial_state)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"üìù FINAL ANSWER\")\n",
    "            print(\"=\"*80)\n",
    "            print(final_state[\"answer\"])\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"üìä METADATA\")\n",
    "            print(\"=\"*80)\n",
    "            metadata = final_state.get(\"metadata\", {})\n",
    "            print(f\"Databricks Results: {metadata.get('vector_results_count', 0)}\")\n",
    "            print(f\"Web Results: {metadata.get('web_results_count', 0)}\")\n",
    "            print(f\"Confidence: {final_state.get('confidence', 0):.2%}\")\n",
    "            \n",
    "            if final_state.get(\"sources\"):\n",
    "                print(\"\\n\" + \"=\"*80)\n",
    "                print(\"üìö SOURCES\")\n",
    "                print(\"=\"*80)\n",
    "                for i, source in enumerate(final_state[\"sources\"], 1):\n",
    "                    print(f\"{i}. {source}\")\n",
    "        \n",
    "        return final_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {\"answer\": f\"Error: {e}\", \"sources\": []}\n",
    "\n",
    "print(\"‚úÖ Query helper function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. Example 1: Query Using Databricks Vector Search Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Internal knowledge query\n",
    "result1 = ask_databricks_rag(\"What is Unity Catalog and how does it work with Delta Lake?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24. Example 2: Query Using Web Search Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Current events query\n",
    "result2 = ask_databricks_rag(\"What are the latest Databricks product announcements in 2024?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25. Example 3: Hybrid Query (Both Sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Hybrid query\n",
    "result3 = ask_databricks_rag(\n",
    "    \"How does Databricks Vector Search compare to other vector databases like Pinecone?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 26. Example 4: Company Policy Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Company policy\n",
    "result4 = ask_databricks_rag(\"What is our company's data governance policy?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27. Add New Documents to Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_documents_to_databricks(\n",
    "    documents: List[Dict[str, Any]],\n",
    "    table_name: str = FULL_TABLE_NAME\n",
    "):\n",
    "    \"\"\"\n",
    "    Add new documents to Databricks Vector Search.\n",
    "    \n",
    "    In production, this would:\n",
    "    1. Generate embeddings\n",
    "    2. Insert into Delta table\n",
    "    3. Vector Search automatically syncs\n",
    "    \"\"\"\n",
    "    print(f\"üìù Adding {len(documents)} documents to Databricks...\")\n",
    "    \n",
    "    # Generate embeddings\n",
    "    for doc in documents:\n",
    "        text_to_embed = f\"{doc['title']}: {doc['content']}\"\n",
    "        doc['embedding'] = embeddings_model.embed_query(text_to_embed)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    new_docs_df = pd.DataFrame(documents)\n",
    "    \n",
    "    # In Databricks notebook with Spark:\n",
    "    spark_code = f\"\"\"\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "spark_df = spark.createDataFrame(new_docs_df)\n",
    "spark_df = spark_df.withColumn(\"created_at\", current_timestamp())\n",
    "\n",
    "# Append to existing table\n",
    "spark_df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .saveAsTable(\"{table_name}\")\n",
    "\n",
    "print(f\"‚úÖ Added {{len(documents)}} documents to {{table_name}}\")\n",
    "\n",
    "# Vector Search will automatically sync the new data\n",
    "print(\"‚è≥ Vector Search will sync automatically (may take a few minutes)\")\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"\\nRun this code in your Databricks notebook:\")\n",
    "    print(spark_code)\n",
    "    \n",
    "    return new_docs_df\n",
    "\n",
    "# Example: Add a new document\n",
    "new_documents = [\n",
    "    {\n",
    "        \"id\": \"doc_008\",\n",
    "        \"content\": \"\"\"Databricks Model Serving provides a unified interface for deploying \n",
    "        and serving ML models at scale. It supports both real-time and batch inference, \n",
    "        automatic scaling, and A/B testing capabilities.\"\"\",\n",
    "        \"title\": \"Databricks Model Serving\",\n",
    "        \"category\": \"ml_serving\",\n",
    "        \"source\": \"model_serving_docs\",\n",
    "        \"date\": \"2024-02-10\"\n",
    "    }\n",
    "]\n",
    "\n",
    "new_docs_df = add_documents_to_databricks(new_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28. Monitor Vector Search Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_status():\n",
    "    \"\"\"\n",
    "    Check the status of the vector search index.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        index = vector_search_client.get_index(\n",
    "            endpoint_name=VECTOR_SEARCH_ENDPOINT,\n",
    "            index_name=FULL_INDEX_NAME\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä VECTOR SEARCH INDEX STATUS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Index Name: {FULL_INDEX_NAME}\")\n",
    "        print(f\"Endpoint: {VECTOR_SEARCH_ENDPOINT}\")\n",
    "        print(f\"Source Table: {FULL_TABLE_NAME}\")\n",
    "        print(f\"\\nStatus: Check Databricks UI for detailed metrics\")\n",
    "        print(f\"Path: Compute > Vector Search > {VECTOR_SEARCH_ENDPOINT}\")\n",
    "        \n",
    "        return index\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error getting index status: {e}\")\n",
    "        return None\n",
    "\n",
    "# Check status\n",
    "index_status = get_index_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 29. Production Deployment Checklist\n",
    "\n",
    "### 1. Infrastructure Setup\n",
    "- ‚úÖ Create dedicated Databricks workspace for production\n",
    "- ‚úÖ Set up Unity Catalog with proper governance\n",
    "- ‚úÖ Configure Vector Search endpoint (HIGH_CONCURRENCY for production)\n",
    "- ‚úÖ Set up Delta tables with appropriate partitioning\n",
    "\n",
    "### 2. Security & Governance\n",
    "- ‚úÖ Implement row-level and column-level security\n",
    "- ‚úÖ Set up audit logging\n",
    "- ‚úÖ Configure access controls (AAD/OAuth)\n",
    "- ‚úÖ Enable data lineage tracking\n",
    "- ‚úÖ Encrypt sensitive data\n",
    "\n",
    "### 3. Performance Optimization\n",
    "- ‚úÖ Optimize embedding generation (batch processing)\n",
    "- ‚úÖ Implement caching for frequent queries\n",
    "- ‚úÖ Set up continuous indexing for real-time updates\n",
    "- ‚úÖ Monitor query latency and throughput\n",
    "- ‚úÖ Use Z-ordering for Delta tables\n",
    "\n",
    "### 4. Monitoring & Observability\n",
    "- ‚úÖ Set up MLflow tracking for model versions\n",
    "- ‚úÖ Implement logging for all RAG operations\n",
    "- ‚úÖ Create dashboards for system metrics\n",
    "- ‚úÖ Set up alerts for anomalies\n",
    "- ‚úÖ Track user feedback and quality metrics\n",
    "\n",
    "### 5. Cost Optimization\n",
    "- ‚úÖ Use appropriate cluster sizes\n",
    "- ‚úÖ Implement auto-scaling\n",
    "- ‚úÖ Monitor compute and storage costs\n",
    "- ‚úÖ Optimize query patterns\n",
    "- ‚úÖ Consider spot instances for non-critical workloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30. Best Practices & Troubleshooting\n",
    "\n",
    "### Vector Search Best Practices\n",
    "\n",
    "**1. Index Management:**\n",
    "```python\n",
    "# Use CONTINUOUS sync for real-time updates\n",
    "pipeline_type=\"CONTINUOUS\"\n",
    "\n",
    "# Use TRIGGERED for batch updates\n",
    "pipeline_type=\"TRIGGERED\"\n",
    "```\n",
    "\n",
    "**2. Query Optimization:**\n",
    "- Use appropriate `num_results` (3-5 for most cases)\n",
    "- Add filters for better relevance\n",
    "- Leverage metadata for filtering\n",
    "\n",
    "**3. Embedding Strategy:**\n",
    "- Combine title and content for richer embeddings\n",
    "- Normalize text before embedding\n",
    "- Use consistent embedding models\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**Issue 1: Index Not Found**\n",
    "- Verify index name is fully qualified (catalog.schema.index)\n",
    "- Check index creation completed successfully\n",
    "- Ensure endpoint is ONLINE\n",
    "\n",
    "**Issue 2: Slow Queries**\n",
    "- Check index sync status\n",
    "- Optimize table partitioning\n",
    "- Use column pruning in queries\n",
    "- Consider increasing endpoint capacity\n",
    "\n",
    "**Issue 3: Poor Result Quality**\n",
    "- Improve document chunking strategy\n",
    "- Enhance metadata richness\n",
    "- Try different embedding models\n",
    "- Implement reranking\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Databricks Vector Search Docs](https://docs.databricks.com/en/generative-ai/vector-search.html)\n",
    "- [Unity Catalog Guide](https://docs.databricks.com/en/data-governance/unity-catalog/index.html)\n",
    "- [Delta Lake Documentation](https://docs.delta.io/)\n",
    "- [LangChain Databricks Integration](https://python.langchain.com/docs/integrations/vectorstores/databricks_vector_search)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
