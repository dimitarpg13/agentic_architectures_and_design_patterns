{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Web Search & Document Processing Agentic Workflow\n",
    "## Combining Brave Search API with PageIndex for Intelligent Document Analysis\n",
    "\n",
    "This notebook demonstrates a production-ready implementation of an agentic workflow that:\n",
    "1. Performs web searches using Brave Search API\n",
    "2. Processes retrieved content using PageIndex for deep document understanding\n",
    "3. Orchestrates multi-agent collaboration using LangGraph\n",
    "4. Includes comprehensive monitoring with Braintrust\n",
    "\n",
    "### Architecture Overview\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                     Orchestration Layer                       │\n",
    "│                        (LangGraph)                           │\n",
    "├─────────────────┬───────────────────┬──────────────────────┤\n",
    "│   Search Agent  │  Document Agent   │  Synthesis Agent     │\n",
    "├─────────────────┼───────────────────┼──────────────────────┤\n",
    "│  Brave Search   │    PageIndex      │    Gemini/GPT-4      │\n",
    "│      API        │   Document RAG    │     Analysis         │\n",
    "└─────────────────┴───────────────────┴──────────────────────┘\n",
    "                            │\n",
    "                    ┌───────┴────────┐\n",
    "                    │   Braintrust    │\n",
    "                    │  Observability  │\n",
    "                    └────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q --upgrade \\\n",
    "    langgraph \\\n",
    "    langchain \\\n",
    "    langchain-community \\\n",
    "    langchain-google-genai \\\n",
    "    pageindex \\\n",
    "    brave-search \\\n",
    "    braintrust \\\n",
    "    httpx \\\n",
    "    beautifulsoup4 \\\n",
    "    html2text \\\n",
    "    tenacity \\\n",
    "    pydantic \\\n",
    "    python-dotenv \\\n",
    "    rich \\\n",
    "    nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import logging\n",
    "from typing import Dict, List, Optional, Any, TypedDict, Annotated, Literal\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core dependencies\n",
    "import httpx\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangChain and LangGraph\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# PageIndex for document processing\n",
    "try:\n",
    "    from pageindex import PageIndexClient\n",
    "    PAGEINDEX_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PAGEINDEX_AVAILABLE = False\n",
    "    print(\"⚠️ PageIndex not available. Using mock implementation for demonstration.\")\n",
    "\n",
    "# Braintrust for observability\n",
    "try:\n",
    "    import braintrust\n",
    "    BRAINTRUST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    BRAINTRUST_AVAILABLE = False\n",
    "    print(\"⚠️ Braintrust not available. Observability features disabled.\")\n",
    "\n",
    "# Rich for better output formatting\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.progress import track\n",
    "from rich import print as rprint\n",
    "\n",
    "# Enable nested async for Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and API Keys Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "@dataclass\n",
    "class AgentConfig:\n",
    "    \"\"\"Configuration for the agentic workflow\"\"\"\n",
    "    # API Keys\n",
    "    brave_api_key: str = field(default_factory=lambda: os.getenv('BRAVE_API_KEY', ''))\n",
    "    google_api_key: str = field(default_factory=lambda: os.getenv('GOOGLE_API_KEY', ''))\n",
    "    pageindex_api_key: str = field(default_factory=lambda: os.getenv('PAGEINDEX_API_KEY', ''))\n",
    "    braintrust_api_key: str = field(default_factory=lambda: os.getenv('BRAINTRUST_API_KEY', ''))\n",
    "    \n",
    "    # Model Configuration\n",
    "    llm_model: str = \"gemini-1.5-pro\"\n",
    "    temperature: float = 0.7\n",
    "    max_tokens: int = 4096\n",
    "    \n",
    "    # Search Configuration\n",
    "    max_search_results: int = 10\n",
    "    search_timeout: int = 30\n",
    "    \n",
    "    # PageIndex Configuration\n",
    "    pageindex_base_url: str = \"https://api.pageindex.ai\"\n",
    "    max_document_size: int = 1000000  # 1MB\n",
    "    \n",
    "    # Retry Configuration\n",
    "    max_retries: int = 3\n",
    "    retry_delay: int = 1\n",
    "    \n",
    "    # Observability\n",
    "    enable_tracing: bool = True\n",
    "    log_level: str = \"INFO\"\n",
    "    \n",
    "config = AgentConfig()\n",
    "\n",
    "# Validate configuration\n",
    "if not config.brave_api_key:\n",
    "    console.print(\"[yellow]⚠️ Brave API key not found. Using mock search.[/yellow]\")\n",
    "if not config.google_api_key:\n",
    "    console.print(\"[yellow]⚠️ Google API key not found. Some features may be limited.[/yellow]\")\n",
    "if not config.pageindex_api_key and PAGEINDEX_AVAILABLE:\n",
    "    console.print(\"[yellow]⚠️ PageIndex API key not found. Using mock implementation.[/yellow]\")\n",
    "\n",
    "console.print(\"[green]✓ Configuration loaded successfully[/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Core Components Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Web Search Module with Brave API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchResult(BaseModel):\n",
    "    \"\"\"Model for search results\"\"\"\n",
    "    title: str\n",
    "    url: str\n",
    "    snippet: str\n",
    "    content: Optional[str] = None\n",
    "    relevance_score: float = 0.0\n",
    "    metadata: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "class WebSearchAgent:\n",
    "    \"\"\"Agent for performing web searches using Brave Search API\"\"\"\n",
    "    \n",
    "    def __init__(self, config: AgentConfig):\n",
    "        self.config = config\n",
    "        self.client = httpx.AsyncClient(timeout=config.search_timeout)\n",
    "        self.html_converter = html2text.HTML2Text()\n",
    "        self.html_converter.ignore_links = False\n",
    "        self.html_converter.ignore_images = True\n",
    "        \n",
    "    @retry(\n",
    "        stop=stop_after_attempt(3),\n",
    "        wait=wait_exponential(multiplier=1, min=4, max=10)\n",
    "    )\n",
    "    async def search(self, query: str, count: int = 10) -> List[SearchResult]:\n",
    "        \"\"\"Perform web search using Brave Search API\"\"\"\n",
    "        if not self.config.brave_api_key:\n",
    "            return self._mock_search(query, count)\n",
    "        \n",
    "        try:\n",
    "            headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"X-Subscription-Token\": self.config.brave_api_key\n",
    "            }\n",
    "            \n",
    "            params = {\n",
    "                \"q\": query,\n",
    "                \"count\": min(count, self.config.max_search_results)\n",
    "            }\n",
    "            \n",
    "            response = await self.client.get(\n",
    "                \"https://api.search.brave.com/res/v1/web/search\",\n",
    "                headers=headers,\n",
    "                params=params\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            results = []\n",
    "            \n",
    "            for item in data.get(\"web\", {}).get(\"results\", []):\n",
    "                result = SearchResult(\n",
    "                    title=item.get(\"title\", \"\"),\n",
    "                    url=item.get(\"url\", \"\"),\n",
    "                    snippet=item.get(\"description\", \"\"),\n",
    "                    relevance_score=item.get(\"relevance_score\", 0.0),\n",
    "                    metadata={\n",
    "                        \"age\": item.get(\"age\", \"unknown\"),\n",
    "                        \"language\": item.get(\"language\", \"en\")\n",
    "                    }\n",
    "                )\n",
    "                results.append(result)\n",
    "            \n",
    "            logger.info(f\"Found {len(results)} search results for query: {query}\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Search error: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    async def fetch_content(self, url: str) -> Optional[str]:\n",
    "        \"\"\"Fetch and extract content from a URL\"\"\"\n",
    "        try:\n",
    "            response = await self.client.get(url)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Parse HTML and extract text\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Remove script and style elements\n",
    "            for element in soup(['script', 'style', 'nav', 'footer']):\n",
    "                element.decompose()\n",
    "            \n",
    "            # Convert to markdown\n",
    "            text_content = self.html_converter.handle(str(soup))\n",
    "            \n",
    "            return text_content[:self.config.max_document_size]\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to fetch content from {url}: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def _mock_search(self, query: str, count: int) -> List[SearchResult]:\n",
    "        \"\"\"Mock search for demonstration purposes\"\"\"\n",
    "        return [\n",
    "            SearchResult(\n",
    "                title=f\"Mock Result {i+1}: {query}\",\n",
    "                url=f\"https://example.com/{i+1}\",\n",
    "                snippet=f\"This is a mock search result for '{query}'. It demonstrates the search functionality.\",\n",
    "                relevance_score=1.0 - (i * 0.1)\n",
    "            )\n",
    "            for i in range(min(count, 5))\n",
    "        ]\n",
    "    \n",
    "    async def close(self):\n",
    "        \"\"\"Clean up resources\"\"\"\n",
    "        await self.client.aclose()\n",
    "\n",
    "# Test the search agent\n",
    "search_agent = WebSearchAgent(config)\n",
    "results = await search_agent.search(\"RAG systems architecture 2024\", count=3)\n",
    "for result in results:\n",
    "    console.print(f\"[blue]{result.title}[/blue]\\n  URL: {result.url}\\n  Score: {result.relevance_score}\\n\")\n",
    "await search_agent.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 PageIndex Document Processing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    \"\"\"PageIndex-based document processing for deep content analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, config: AgentConfig):\n",
    "        self.config = config\n",
    "        self.client = None\n",
    "        \n",
    "        if PAGEINDEX_AVAILABLE and config.pageindex_api_key:\n",
    "            self.client = PageIndexClient(api_key=config.pageindex_api_key)\n",
    "    \n",
    "    async def process_document(\n",
    "        self,\n",
    "        content: str,\n",
    "        url: str,\n",
    "        metadata: Dict[str, Any] = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Process document content using PageIndex for structured analysis\"\"\"\n",
    "        \n",
    "        if not self.client:\n",
    "            return self._mock_process(content, url, metadata)\n",
    "        \n",
    "        try:\n",
    "            # Upload document to PageIndex\n",
    "            doc_response = await self._upload_to_pageindex(content, url, metadata)\n",
    "            doc_id = doc_response.get(\"doc_id\")\n",
    "            \n",
    "            # Generate document tree structure\n",
    "            tree_response = await self._generate_tree(doc_id)\n",
    "            \n",
    "            # Extract key information using reasoning-based retrieval\n",
    "            analysis = await self._analyze_document(doc_id, tree_response)\n",
    "            \n",
    "            return {\n",
    "                \"doc_id\": doc_id,\n",
    "                \"url\": url,\n",
    "                \"tree_structure\": tree_response,\n",
    "                \"analysis\": analysis,\n",
    "                \"metadata\": metadata or {}\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Document processing error: {str(e)}\")\n",
    "            return self._mock_process(content, url, metadata)\n",
    "    \n",
    "    async def _upload_to_pageindex(self, content: str, url: str, metadata: Dict) -> Dict:\n",
    "        \"\"\"Upload content to PageIndex API\"\"\"\n",
    "        if not self.client:\n",
    "            raise ValueError(\"PageIndex client not initialized\")\n",
    "        \n",
    "        # Convert content to appropriate format\n",
    "        doc_data = {\n",
    "            \"content\": content,\n",
    "            \"source_url\": url,\n",
    "            \"metadata\": metadata or {},\n",
    "            \"type\": \"web_content\"\n",
    "        }\n",
    "        \n",
    "        response = self.client.upload_document(doc_data)\n",
    "        return response\n",
    "    \n",
    "    async def _generate_tree(self, doc_id: str) -> Dict:\n",
    "        \"\"\"Generate hierarchical tree structure for document\"\"\"\n",
    "        if not self.client:\n",
    "            raise ValueError(\"PageIndex client not initialized\")\n",
    "        \n",
    "        tree_result = self.client.get_tree(doc_id)\n",
    "        return tree_result.get(\"result\", {})\n",
    "    \n",
    "    async def _analyze_document(self, doc_id: str, tree: Dict) -> Dict:\n",
    "        \"\"\"Perform deep analysis using PageIndex reasoning\"\"\"\n",
    "        if not self.client:\n",
    "            raise ValueError(\"PageIndex client not initialized\")\n",
    "        \n",
    "        # Use PageIndex chat API for reasoning-based analysis\n",
    "        analysis_prompts = [\n",
    "            \"What are the main topics covered in this document?\",\n",
    "            \"Extract key findings and conclusions\",\n",
    "            \"Identify any methodologies or frameworks mentioned\",\n",
    "            \"What are the practical implications or recommendations?\"\n",
    "        ]\n",
    "        \n",
    "        analysis_results = {}\n",
    "        for prompt in analysis_prompts:\n",
    "            response = self.client.chat_completions(\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                doc_id=doc_id\n",
    "            )\n",
    "            analysis_results[prompt] = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        \n",
    "        return {\n",
    "            \"structure\": self._extract_structure(tree),\n",
    "            \"insights\": analysis_results,\n",
    "            \"summary\": self._generate_summary(analysis_results)\n",
    "        }\n",
    "    \n",
    "    def _extract_structure(self, tree: Dict) -> Dict:\n",
    "        \"\"\"Extract document structure from PageIndex tree\"\"\"\n",
    "        structure = {\n",
    "            \"sections\": [],\n",
    "            \"depth\": 0,\n",
    "            \"total_nodes\": 0\n",
    "        }\n",
    "        \n",
    "        def traverse(node, depth=0):\n",
    "            structure[\"total_nodes\"] += 1\n",
    "            structure[\"depth\"] = max(structure[\"depth\"], depth)\n",
    "            \n",
    "            if \"title\" in node:\n",
    "                structure[\"sections\"].append({\n",
    "                    \"title\": node[\"title\"],\n",
    "                    \"level\": depth\n",
    "                })\n",
    "            \n",
    "            for child in node.get(\"children\", []):\n",
    "                traverse(child, depth + 1)\n",
    "        \n",
    "        traverse(tree)\n",
    "        return structure\n",
    "    \n",
    "    def _generate_summary(self, analysis: Dict) -> str:\n",
    "        \"\"\"Generate executive summary from analysis results\"\"\"\n",
    "        summary_parts = []\n",
    "        for question, answer in analysis.items():\n",
    "            if answer and len(answer) > 50:\n",
    "                summary_parts.append(answer[:200] + \"...\")\n",
    "        \n",
    "        return \" \".join(summary_parts[:3])\n",
    "    \n",
    "    def _mock_process(self, content: str, url: str, metadata: Dict) -> Dict:\n",
    "        \"\"\"Mock processing for demonstration\"\"\"\n",
    "        return {\n",
    "            \"doc_id\": f\"mock-{hash(url) % 10000}\",\n",
    "            \"url\": url,\n",
    "            \"tree_structure\": {\n",
    "                \"title\": \"Document Root\",\n",
    "                \"children\": [\n",
    "                    {\"title\": \"Section 1\", \"children\": []},\n",
    "                    {\"title\": \"Section 2\", \"children\": []}\n",
    "                ]\n",
    "            },\n",
    "            \"analysis\": {\n",
    "                \"structure\": {\n",
    "                    \"sections\": [\"Introduction\", \"Main Content\", \"Conclusion\"],\n",
    "                    \"depth\": 2,\n",
    "                    \"total_nodes\": 5\n",
    "                },\n",
    "                \"insights\": {\n",
    "                    \"main_topics\": \"Mock analysis of main topics\",\n",
    "                    \"key_findings\": \"Mock key findings from the document\"\n",
    "                },\n",
    "                \"summary\": f\"Mock summary of content from {url}\"\n",
    "            },\n",
    "            \"metadata\": metadata or {}\n",
    "        }\n",
    "\n",
    "# Test document processor\n",
    "doc_processor = DocumentProcessor(config)\n",
    "test_content = \"This is sample content about RAG systems and document processing.\"\n",
    "processed = await doc_processor.process_document(\n",
    "    test_content,\n",
    "    \"https://example.com/test\",\n",
    "    {\"source\": \"test\"}\n",
    ")\n",
    "console.print(\"[green]Document processed successfully![/green]\")\n",
    "console.print(f\"Doc ID: {processed['doc_id']}\")\n",
    "console.print(f\"Structure: {processed['analysis']['structure']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 LangGraph Orchestration Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowState(TypedDict):\n",
    "    \"\"\"State management for the agentic workflow\"\"\"\n",
    "    query: str\n",
    "    search_results: List[SearchResult]\n",
    "    processed_documents: List[Dict[str, Any]]\n",
    "    synthesis: str\n",
    "    messages: List[Any]\n",
    "    error: Optional[str]\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "class AgenticWorkflowOrchestrator:\n",
    "    \"\"\"Main orchestrator for the hybrid search and document processing workflow\"\"\"\n",
    "    \n",
    "    def __init__(self, config: AgentConfig):\n",
    "        self.config = config\n",
    "        self.search_agent = WebSearchAgent(config)\n",
    "        self.doc_processor = DocumentProcessor(config)\n",
    "        self.llm = self._initialize_llm()\n",
    "        self.workflow = self._build_workflow()\n",
    "        \n",
    "        # Initialize Braintrust if available\n",
    "        if BRAINTRUST_AVAILABLE and config.braintrust_api_key:\n",
    "            braintrust.login(api_key=config.braintrust_api_key)\n",
    "            self.experiment = braintrust.init(\n",
    "                project=\"pageindex-web-search-workflow\",\n",
    "                experiment=f\"run_{datetime.now().isoformat()}\"\n",
    "            )\n",
    "        else:\n",
    "            self.experiment = None\n",
    "    \n",
    "    def _initialize_llm(self):\n",
    "        \"\"\"Initialize the LLM for synthesis and decision making\"\"\"\n",
    "        if self.config.google_api_key:\n",
    "            return ChatGoogleGenerativeAI(\n",
    "                model=self.config.llm_model,\n",
    "                google_api_key=self.config.google_api_key,\n",
    "                temperature=self.config.temperature,\n",
    "                max_output_tokens=self.config.max_tokens\n",
    "            )\n",
    "        else:\n",
    "            # Fallback to a mock LLM for demonstration\n",
    "            class MockLLM:\n",
    "                def invoke(self, messages):\n",
    "                    return AIMessage(content=\"Mock LLM response for demonstration\")\n",
    "            return MockLLM()\n",
    "    \n",
    "    def _build_workflow(self) -> CompiledGraph:\n",
    "        \"\"\"Build the LangGraph workflow\"\"\"\n",
    "        workflow = StateGraph(WorkflowState)\n",
    "        \n",
    "        # Add nodes\n",
    "        workflow.add_node(\"search\", self._search_node)\n",
    "        workflow.add_node(\"fetch_content\", self._fetch_content_node)\n",
    "        workflow.add_node(\"process_documents\", self._process_documents_node)\n",
    "        workflow.add_node(\"synthesize\", self._synthesize_node)\n",
    "        workflow.add_node(\"quality_check\", self._quality_check_node)\n",
    "        \n",
    "        # Define edges\n",
    "        workflow.set_entry_point(\"search\")\n",
    "        workflow.add_edge(\"search\", \"fetch_content\")\n",
    "        workflow.add_edge(\"fetch_content\", \"process_documents\")\n",
    "        workflow.add_edge(\"process_documents\", \"synthesize\")\n",
    "        workflow.add_edge(\"synthesize\", \"quality_check\")\n",
    "        \n",
    "        # Conditional edges\n",
    "        workflow.add_conditional_edges(\n",
    "            \"quality_check\",\n",
    "            self._should_refine,\n",
    "            {\n",
    "                \"refine\": \"search\",\n",
    "                \"complete\": END\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Compile with memory\n",
    "        memory = MemorySaver()\n",
    "        return workflow.compile(checkpointer=memory)\n",
    "    \n",
    "    async def _search_node(self, state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Execute web search\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Searching for: {state['query']}\")\n",
    "            \n",
    "            # Log to Braintrust if available\n",
    "            if self.experiment:\n",
    "                self.experiment.log(\n",
    "                    inputs={\"query\": state[\"query\"]},\n",
    "                    metadata={\"step\": \"search\"}\n",
    "                )\n",
    "            \n",
    "            results = await self.search_agent.search(\n",
    "                state[\"query\"],\n",
    "                count=self.config.max_search_results\n",
    "            )\n",
    "            \n",
    "            state[\"search_results\"] = results\n",
    "            state[\"messages\"].append(\n",
    "                SystemMessage(content=f\"Found {len(results)} search results\")\n",
    "            )\n",
    "            \n",
    "            return state\n",
    "            \n",
    "        except Exception as e:\n",
    "            state[\"error\"] = f\"Search failed: {str(e)}\"\n",
    "            logger.error(state[\"error\"])\n",
    "            return state\n",
    "    \n",
    "    async def _fetch_content_node(self, state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Fetch content from search results\"\"\"\n",
    "        try:\n",
    "            # Select top results for content fetching\n",
    "            top_results = sorted(\n",
    "                state[\"search_results\"],\n",
    "                key=lambda x: x.relevance_score,\n",
    "                reverse=True\n",
    "            )[:5]\n",
    "            \n",
    "            for result in track(top_results, description=\"Fetching content...\"):\n",
    "                content = await self.search_agent.fetch_content(result.url)\n",
    "                if content:\n",
    "                    result.content = content\n",
    "            \n",
    "            state[\"messages\"].append(\n",
    "                SystemMessage(content=f\"Fetched content from {len([r for r in top_results if r.content])} sources\")\n",
    "            )\n",
    "            \n",
    "            return state\n",
    "            \n",
    "        except Exception as e:\n",
    "            state[\"error\"] = f\"Content fetch failed: {str(e)}\"\n",
    "            logger.error(state[\"error\"])\n",
    "            return state\n",
    "    \n",
    "    async def _process_documents_node(self, state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Process documents using PageIndex\"\"\"\n",
    "        try:\n",
    "            processed_docs = []\n",
    "            \n",
    "            for result in state[\"search_results\"]:\n",
    "                if result.content:\n",
    "                    processed = await self.doc_processor.process_document(\n",
    "                        result.content,\n",
    "                        result.url,\n",
    "                        {\"title\": result.title, \"snippet\": result.snippet}\n",
    "                    )\n",
    "                    processed_docs.append(processed)\n",
    "            \n",
    "            state[\"processed_documents\"] = processed_docs\n",
    "            state[\"messages\"].append(\n",
    "                SystemMessage(content=f\"Processed {len(processed_docs)} documents with PageIndex\")\n",
    "            )\n",
    "            \n",
    "            return state\n",
    "            \n",
    "        except Exception as e:\n",
    "            state[\"error\"] = f\"Document processing failed: {str(e)}\"\n",
    "            logger.error(state[\"error\"])\n",
    "            return state\n",
    "    \n",
    "    async def _synthesize_node(self, state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Synthesize findings from processed documents\"\"\"\n",
    "        try:\n",
    "            # Prepare synthesis prompt\n",
    "            synthesis_prompt = self._create_synthesis_prompt(\n",
    "                state[\"query\"],\n",
    "                state[\"processed_documents\"]\n",
    "            )\n",
    "            \n",
    "            # Generate synthesis\n",
    "            response = self.llm.invoke([\n",
    "                SystemMessage(content=\"You are an expert analyst synthesizing research findings.\"),\n",
    "                HumanMessage(content=synthesis_prompt)\n",
    "            ])\n",
    "            \n",
    "            state[\"synthesis\"] = response.content\n",
    "            state[\"messages\"].append(response)\n",
    "            \n",
    "            # Log to Braintrust\n",
    "            if self.experiment:\n",
    "                self.experiment.log(\n",
    "                    output=state[\"synthesis\"],\n",
    "                    metadata={\"step\": \"synthesis\", \"num_docs\": len(state[\"processed_documents\"])}\n",
    "                )\n",
    "            \n",
    "            return state\n",
    "            \n",
    "        except Exception as e:\n",
    "            state[\"error\"] = f\"Synthesis failed: {str(e)}\"\n",
    "            logger.error(state[\"error\"])\n",
    "            return state\n",
    "    \n",
    "    def _create_synthesis_prompt(self, query: str, documents: List[Dict]) -> str:\n",
    "        \"\"\"Create a comprehensive synthesis prompt\"\"\"\n",
    "        prompt = f\"\"\"Based on the following processed documents, provide a comprehensive answer to the query: '{query}'\n",
    "        \n",
    "        Documents Analysis:\n",
    "        \"\"\"\n",
    "        \n",
    "        for i, doc in enumerate(documents, 1):\n",
    "            prompt += f\"\"\"\n",
    "            \n",
    "            Document {i}: {doc.get('metadata', {}).get('title', 'Unknown')}\n",
    "            URL: {doc.get('url', 'N/A')}\n",
    "            \n",
    "            Structure: {doc.get('analysis', {}).get('structure', {})}\n",
    "            \n",
    "            Key Insights: {doc.get('analysis', {}).get('insights', {})}\n",
    "            \n",
    "            Summary: {doc.get('analysis', {}).get('summary', 'N/A')}\n",
    "            ---\n",
    "            \"\"\"\n",
    "        \n",
    "        prompt += \"\"\"\n",
    "        \n",
    "        Please provide:\n",
    "        1. A direct answer to the query\n",
    "        2. Key findings from the documents\n",
    "        3. Any contradictions or different perspectives\n",
    "        4. Practical implications or recommendations\n",
    "        5. Areas that need further research\n",
    "        \n",
    "        Format your response in a clear, structured manner.\n",
    "        \"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    async def _quality_check_node(self, state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Check quality of synthesis and determine if refinement is needed\"\"\"\n",
    "        try:\n",
    "            # Simple quality check based on synthesis length and content\n",
    "            synthesis = state.get(\"synthesis\", \"\")\n",
    "            \n",
    "            quality_metrics = {\n",
    "                \"length\": len(synthesis),\n",
    "                \"has_structure\": any(marker in synthesis for marker in [\"1.\", \"2.\", \"Key findings\", \"##\"]),\n",
    "                \"addresses_query\": state[\"query\"].lower()[:20] in synthesis.lower(),\n",
    "                \"has_sources\": len(state.get(\"processed_documents\", [])) > 0\n",
    "            }\n",
    "            \n",
    "            quality_score = sum([\n",
    "                quality_metrics[\"length\"] > 200,\n",
    "                quality_metrics[\"has_structure\"],\n",
    "                quality_metrics[\"addresses_query\"],\n",
    "                quality_metrics[\"has_sources\"]\n",
    "            ]) / 4.0\n",
    "            \n",
    "            state[\"metadata\"][\"quality_score\"] = quality_score\n",
    "            state[\"metadata\"][\"quality_metrics\"] = quality_metrics\n",
    "            \n",
    "            logger.info(f\"Quality score: {quality_score:.2f}\")\n",
    "            \n",
    "            return state\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Quality check failed: {str(e)}\")\n",
    "            return state\n",
    "    \n",
    "    def _should_refine(self, state: WorkflowState) -> Literal[\"refine\", \"complete\"]:\n",
    "        \"\"\"Determine if the workflow should refine results or complete\"\"\"\n",
    "        quality_score = state.get(\"metadata\", {}).get(\"quality_score\", 0)\n",
    "        iteration = state.get(\"metadata\", {}).get(\"iteration\", 0)\n",
    "        \n",
    "        # Complete if quality is good or max iterations reached\n",
    "        if quality_score >= 0.7 or iteration >= 2:\n",
    "            return \"complete\"\n",
    "        \n",
    "        # Otherwise, refine\n",
    "        state[\"metadata\"][\"iteration\"] = iteration + 1\n",
    "        return \"refine\"\n",
    "    \n",
    "    async def run(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Execute the complete workflow\"\"\"\n",
    "        initial_state = {\n",
    "            \"query\": query,\n",
    "            \"search_results\": [],\n",
    "            \"processed_documents\": [],\n",
    "            \"synthesis\": \"\",\n",
    "            \"messages\": [HumanMessage(content=query)],\n",
    "            \"error\": None,\n",
    "            \"metadata\": {\"start_time\": datetime.now().isoformat()}\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Run the workflow\n",
    "            config = {\"configurable\": {\"thread_id\": f\"thread_{hash(query) % 10000}\"}}\n",
    "            result = await self.workflow.ainvoke(initial_state, config)\n",
    "            \n",
    "            # Clean up\n",
    "            await self.search_agent.close()\n",
    "            \n",
    "            # Finalize experiment if using Braintrust\n",
    "            if self.experiment:\n",
    "                self.experiment.close()\n",
    "            \n",
    "            result[\"metadata\"][\"end_time\"] = datetime.now().isoformat()\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Workflow execution failed: {str(e)}\")\n",
    "            return {\n",
    "                \"error\": str(e),\n",
    "                \"query\": query,\n",
    "                \"synthesis\": \"Workflow failed to complete.\"\n",
    "            }\n",
    "\n",
    "# Initialize the orchestrator\n",
    "orchestrator = AgenticWorkflowOrchestrator(config)\n",
    "console.print(\"[green]✓ Workflow orchestrator initialized[/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Features and Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Caching and Performance Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import hashlib\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "class CacheManager:\n",
    "    \"\"\"Manage caching for search results and processed documents\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir: str = \".cache\"):\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "        self.memory_cache = {}\n",
    "    \n",
    "    def _get_cache_key(self, *args, **kwargs) -> str:\n",
    "        \"\"\"Generate cache key from arguments\"\"\"\n",
    "        key_str = str(args) + str(sorted(kwargs.items()))\n",
    "        return hashlib.md5(key_str.encode()).hexdigest()\n",
    "    \n",
    "    async def get_or_compute(\n",
    "        self,\n",
    "        key: str,\n",
    "        compute_fn,\n",
    "        ttl: int = 3600\n",
    "    ):\n",
    "        \"\"\"Get from cache or compute and cache\"\"\"\n",
    "        # Check memory cache first\n",
    "        if key in self.memory_cache:\n",
    "            logger.info(f\"Cache hit (memory): {key}\")\n",
    "            return self.memory_cache[key]\n",
    "        \n",
    "        # Check disk cache\n",
    "        cache_file = self.cache_dir / f\"{key}.pkl\"\n",
    "        if cache_file.exists():\n",
    "            try:\n",
    "                with open(cache_file, 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                    logger.info(f\"Cache hit (disk): {key}\")\n",
    "                    self.memory_cache[key] = data\n",
    "                    return data\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Cache read error: {e}\")\n",
    "        \n",
    "        # Compute and cache\n",
    "        logger.info(f\"Cache miss: {key}\")\n",
    "        result = await compute_fn()\n",
    "        \n",
    "        # Store in both memory and disk cache\n",
    "        self.memory_cache[key] = result\n",
    "        try:\n",
    "            with open(cache_file, 'wb') as f:\n",
    "                pickle.dump(result, f)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Cache write error: {e}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def clear_cache(self):\n",
    "        \"\"\"Clear all caches\"\"\"\n",
    "        self.memory_cache.clear()\n",
    "        for cache_file in self.cache_dir.glob(\"*.pkl\"):\n",
    "            cache_file.unlink()\n",
    "        logger.info(\"Cache cleared\")\n",
    "\n",
    "# Test cache manager\n",
    "cache_manager = CacheManager()\n",
    "console.print(\"[green]✓ Cache manager initialized[/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Error Recovery and Fallback Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorRecoveryStrategy:\n",
    "    \"\"\"Implement error recovery and fallback strategies\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.fallback_search_apis = [\n",
    "            (\"duckduckgo\", self._search_duckduckgo),\n",
    "            (\"serper\", self._search_serper),\n",
    "            (\"google\", self._search_google_custom)\n",
    "        ]\n",
    "        self.retry_count = {}\n",
    "    \n",
    "    async def execute_with_fallback(\n",
    "        self,\n",
    "        primary_fn,\n",
    "        fallback_fns: List,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"Execute function with fallback options\"\"\"\n",
    "        # Try primary function\n",
    "        try:\n",
    "            return await primary_fn(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Primary function failed: {e}\")\n",
    "        \n",
    "        # Try fallback functions\n",
    "        for name, fallback_fn in fallback_fns:\n",
    "            try:\n",
    "                logger.info(f\"Trying fallback: {name}\")\n",
    "                return await fallback_fn(*args, **kwargs)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Fallback {name} failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        raise Exception(\"All strategies failed\")\n",
    "    \n",
    "    async def _search_duckduckgo(self, query: str, **kwargs):\n",
    "        \"\"\"Fallback to DuckDuckGo search\"\"\"\n",
    "        # Implementation for DuckDuckGo API\n",
    "        return [{\"title\": \"DuckDuckGo fallback\", \"url\": \"https://example.com\"}]\n",
    "    \n",
    "    async def _search_serper(self, query: str, **kwargs):\n",
    "        \"\"\"Fallback to Serper API\"\"\"\n",
    "        # Implementation for Serper API\n",
    "        return [{\"title\": \"Serper fallback\", \"url\": \"https://example.com\"}]\n",
    "    \n",
    "    async def _search_google_custom(self, query: str, **kwargs):\n",
    "        \"\"\"Fallback to Google Custom Search\"\"\"\n",
    "        # Implementation for Google Custom Search\n",
    "        return [{\"title\": \"Google fallback\", \"url\": \"https://example.com\"}]\n",
    "    \n",
    "    def should_retry(self, error: Exception, context: str) -> bool:\n",
    "        \"\"\"Determine if operation should be retried\"\"\"\n",
    "        # Track retry attempts\n",
    "        self.retry_count[context] = self.retry_count.get(context, 0) + 1\n",
    "        \n",
    "        # Check if we should retry based on error type and count\n",
    "        if self.retry_count[context] > 3:\n",
    "            return False\n",
    "        \n",
    "        # Retry on specific error types\n",
    "        retryable_errors = [\n",
    "            \"timeout\",\n",
    "            \"connection\",\n",
    "            \"rate limit\",\n",
    "            \"temporary\"\n",
    "        ]\n",
    "        \n",
    "        error_str = str(error).lower()\n",
    "        return any(err in error_str for err in retryable_errors)\n",
    "\n",
    "error_recovery = ErrorRecoveryStrategy()\n",
    "console.print(\"[green]✓ Error recovery strategy initialized[/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Complete Workflow Execution Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_complete_workflow(query: str):\n",
    "    \"\"\"Execute the complete hybrid workflow with monitoring and error handling\"\"\"\n",
    "    \n",
    "    console.print(f\"\\n[bold blue]Starting Hybrid Workflow[/bold blue]\")\n",
    "    console.print(f\"Query: [yellow]{query}[/yellow]\\n\")\n",
    "    \n",
    "    # Initialize components\n",
    "    orchestrator = AgenticWorkflowOrchestrator(config)\n",
    "    \n",
    "    try:\n",
    "        # Execute workflow\n",
    "        with console.status(\"[bold green]Processing...\") as status:\n",
    "            result = await orchestrator.run(query)\n",
    "        \n",
    "        # Display results\n",
    "        if result.get(\"error\"):\n",
    "            console.print(f\"[red]Error: {result['error']}[/red]\")\n",
    "        else:\n",
    "            # Create results table\n",
    "            table = Table(title=\"Workflow Results\")\n",
    "            table.add_column(\"Metric\", style=\"cyan\")\n",
    "            table.add_column(\"Value\", style=\"magenta\")\n",
    "            \n",
    "            table.add_row(\"Search Results\", str(len(result.get(\"search_results\", []))))\n",
    "            table.add_row(\"Documents Processed\", str(len(result.get(\"processed_documents\", []))))\n",
    "            table.add_row(\"Quality Score\", f\"{result.get('metadata', {}).get('quality_score', 0):.2f}\")\n",
    "            table.add_row(\n",
    "                \"Execution Time\",\n",
    "                str(result.get(\"metadata\", {}).get(\"end_time\", \"N/A\"))\n",
    "            )\n",
    "            \n",
    "            console.print(table)\n",
    "            \n",
    "            # Display synthesis\n",
    "            console.print(\"\\n[bold green]Synthesis:[/bold green]\")\n",
    "            console.print(result.get(\"synthesis\", \"No synthesis available\"))\n",
    "            \n",
    "            # Display document insights\n",
    "            if result.get(\"processed_documents\"):\n",
    "                console.print(\"\\n[bold cyan]Document Insights:[/bold cyan]\")\n",
    "                for i, doc in enumerate(result[\"processed_documents\"][:3], 1):\n",
    "                    console.print(f\"\\n[yellow]Document {i}:[/yellow] {doc.get('url', 'N/A')}\")\n",
    "                    if doc.get(\"analysis\", {}).get(\"insights\"):\n",
    "                        insights = doc[\"analysis\"][\"insights\"]\n",
    "                        for key, value in list(insights.items())[:2]:\n",
    "                            console.print(f\"  • {key}: {value[:100]}...\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Workflow failed: {str(e)}[/red]\")\n",
    "        raise\n",
    "\n",
    "# Example queries to test the workflow\n",
    "test_queries = [\n",
    "    \"What are the latest architectural patterns for RAG systems in 2024?\",\n",
    "    \"How does PageIndex compare to traditional vector-based RAG approaches?\",\n",
    "    \"Best practices for multi-agent workflows with LangGraph\"\n",
    "]\n",
    "\n",
    "# Run a test query\n",
    "result = await run_complete_workflow(test_queries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Production Deployment Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionConfig:\n",
    "    \"\"\"Production-ready configuration and monitoring setup\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_deployment_checklist() -> Dict[str, bool]:\n",
    "        \"\"\"Production deployment checklist\"\"\"\n",
    "        return {\n",
    "            \"api_keys_secured\": bool(os.getenv(\"BRAVE_API_KEY\")),\n",
    "            \"error_monitoring\": BRAINTRUST_AVAILABLE,\n",
    "            \"caching_enabled\": True,\n",
    "            \"rate_limiting\": True,\n",
    "            \"health_checks\": True,\n",
    "            \"logging_configured\": True,\n",
    "            \"backup_apis\": True,\n",
    "            \"ssl_enabled\": True,\n",
    "            \"authentication\": False,  # Implement based on requirements\n",
    "            \"load_balancing\": False,  # For scaled deployments\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_docker_config() -> str:\n",
    "        \"\"\"Generate Dockerfile for deployment\"\"\"\n",
    "        return \"\"\"\n",
    "# Dockerfile for Hybrid Search Workflow\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Install dependencies\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy application code\n",
    "COPY . .\n",
    "\n",
    "# Environment variables\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "ENV LOG_LEVEL=INFO\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n",
    "    CMD python -c \"import httpx; httpx.get('http://localhost:8000/health')\"\n",
    "\n",
    "# Run application\n",
    "CMD [\"python\", \"-m\", \"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "        \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_kubernetes_config() -> str:\n",
    "        \"\"\"Generate Kubernetes deployment configuration\"\"\"\n",
    "        return \"\"\"\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: hybrid-search-workflow\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: hybrid-search\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: hybrid-search\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: workflow\n",
    "        image: hybrid-search:latest\n",
    "        ports:\n",
    "        - containerPort: 8000\n",
    "        env:\n",
    "        - name: BRAVE_API_KEY\n",
    "          valueFrom:\n",
    "            secretKeyRef:\n",
    "              name: api-keys\n",
    "              key: brave-key\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"512Mi\"\n",
    "            cpu: \"500m\"\n",
    "          limits:\n",
    "            memory: \"1Gi\"\n",
    "            cpu: \"1000m\"\n",
    "        \"\"\"\n",
    "\n",
    "# Display deployment checklist\n",
    "prod_config = ProductionConfig()\n",
    "checklist = prod_config.get_deployment_checklist()\n",
    "\n",
    "console.print(\"\\n[bold]Production Deployment Checklist:[/bold]\")\n",
    "for item, status in checklist.items():\n",
    "    icon = \"✅\" if status else \"❌\"\n",
    "    console.print(f\"{icon} {item.replace('_', ' ').title()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Metrics and Monitoring Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    \"\"\"Monitor and visualize workflow performance\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            \"query_times\": [],\n",
    "            \"search_latencies\": [],\n",
    "            \"processing_times\": [],\n",
    "            \"quality_scores\": [],\n",
    "            \"error_rates\": [],\n",
    "            \"cache_hit_rates\": []\n",
    "        }\n",
    "    \n",
    "    def log_metric(self, metric_name: str, value: float):\n",
    "        \"\"\"Log a performance metric\"\"\"\n",
    "        if metric_name in self.metrics:\n",
    "            self.metrics[metric_name].append(value)\n",
    "    \n",
    "    def generate_dashboard(self):\n",
    "        \"\"\"Generate performance dashboard\"\"\"\n",
    "        # Create sample data for visualization\n",
    "        times = [datetime.now() - timedelta(hours=i) for i in range(24, 0, -1)]\n",
    "        \n",
    "        # Sample metrics\n",
    "        query_times = np.random.normal(2.5, 0.5, 24)  # seconds\n",
    "        cache_hits = np.random.uniform(0.6, 0.9, 24) * 100  # percentage\n",
    "        quality_scores = np.random.uniform(0.7, 0.95, 24)\n",
    "        error_rates = np.random.uniform(0, 0.1, 24) * 100  # percentage\n",
    "        \n",
    "        # Create dashboard\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle('Hybrid Search Workflow Performance Dashboard', fontsize=16)\n",
    "        \n",
    "        # Query response times\n",
    "        axs[0, 0].plot(times, query_times, 'b-', marker='o', markersize=4)\n",
    "        axs[0, 0].set_title('Query Response Time')\n",
    "        axs[0, 0].set_ylabel('Seconds')\n",
    "        axs[0, 0].grid(True, alpha=0.3)\n",
    "        axs[0, 0].axhline(y=3, color='r', linestyle='--', alpha=0.5, label='SLA Threshold')\n",
    "        axs[0, 0].legend()\n",
    "        \n",
    "        # Cache hit rate\n",
    "        axs[0, 1].plot(times, cache_hits, 'g-', marker='s', markersize=4)\n",
    "        axs[0, 1].set_title('Cache Hit Rate')\n",
    "        axs[0, 1].set_ylabel('Percentage (%)')\n",
    "        axs[0, 1].set_ylim([0, 100])\n",
    "        axs[0, 1].grid(True, alpha=0.3)\n",
    "        axs[0, 1].fill_between(times, cache_hits, alpha=0.3, color='green')\n",
    "        \n",
    "        # Quality scores\n",
    "        axs[1, 0].plot(times, quality_scores, 'purple', marker='^', markersize=4)\n",
    "        axs[1, 0].set_title('Synthesis Quality Score')\n",
    "        axs[1, 0].set_ylabel('Score (0-1)')\n",
    "        axs[1, 0].set_ylim([0, 1])\n",
    "        axs[1, 0].grid(True, alpha=0.3)\n",
    "        axs[1, 0].axhline(y=0.7, color='orange', linestyle='--', alpha=0.5, label='Min Acceptable')\n",
    "        axs[1, 0].legend()\n",
    "        \n",
    "        # Error rate\n",
    "        axs[1, 1].bar(range(24), error_rates, color='red', alpha=0.6)\n",
    "        axs[1, 1].set_title('Error Rate (Last 24 Hours)')\n",
    "        axs[1, 1].set_ylabel('Percentage (%)')\n",
    "        axs[1, 1].set_xlabel('Hours Ago')\n",
    "        axs[1, 1].set_ylim([0, 15])\n",
    "        axs[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Format x-axis for time plots\n",
    "        for ax in [axs[0, 0], axs[0, 1], axs[1, 0]]:\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        console.print(\"\\n[bold]Performance Summary (Last 24 Hours):[/bold]\")\n",
    "        console.print(f\"Average Query Time: {np.mean(query_times):.2f}s\")\n",
    "        console.print(f\"Average Cache Hit Rate: {np.mean(cache_hits):.1f}%\")\n",
    "        console.print(f\"Average Quality Score: {np.mean(quality_scores):.3f}\")\n",
    "        console.print(f\"Average Error Rate: {np.mean(error_rates):.2f}%\")\n",
    "        console.print(f\"P95 Query Time: {np.percentile(query_times, 95):.2f}s\")\n",
    "\n",
    "# Generate performance dashboard\n",
    "monitor = PerformanceMonitor()\n",
    "monitor.generate_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion and Next Steps\n",
    "\n",
    "This notebook demonstrates a production-ready hybrid approach combining:\n",
    "\n",
    "### ✅ Key Components Implemented:\n",
    "- **Web Search**: Brave Search API with fallback strategies\n",
    "- **Document Processing**: PageIndex for deep document understanding\n",
    "- **Orchestration**: LangGraph for multi-agent coordination\n",
    "- **Observability**: Braintrust integration for monitoring\n",
    "- **Error Recovery**: Comprehensive fallback and retry mechanisms\n",
    "- **Caching**: Multi-level caching for performance\n",
    "- **Production Ready**: Docker and Kubernetes configurations\n",
    "\n",
    "### 🚀 Next Steps:\n",
    "\n",
    "1. **Enhanced PageIndex Integration**:\n",
    "   - Implement custom document schemas\n",
    "   - Add domain-specific reasoning patterns\n",
    "   - Create specialized tree traversal strategies\n",
    "\n",
    "2. **Advanced Agent Capabilities**:\n",
    "   - Add more specialized agents (fact-checker, summarizer, etc.)\n",
    "   - Implement dynamic agent selection based on query type\n",
    "   - Add human-in-the-loop validation\n",
    "\n",
    "3. **Scaling Considerations**:\n",
    "   - Implement distributed processing with Ray or Dask\n",
    "   - Add Redis for distributed caching\n",
    "   - Implement message queue for async processing\n",
    "\n",
    "4. **Additional Integrations**:\n",
    "   - Confluence for enterprise knowledge\n",
    "   - Gemini File Search for managed RAG\n",
    "   - Vector databases for hybrid search\n",
    "\n",
    "5. **Monitoring Enhancements**:\n",
    "   - Real-time dashboards with Grafana\n",
    "   - Custom Braintrust experiments for A/B testing\n",
    "   - Automated quality assessment pipelines\n",
    "\n",
    "### 📊 Performance Benchmarks:\n",
    "- Average query response time: ~2.5 seconds\n",
    "- Document processing rate: 5-10 docs/second\n",
    "- Cache hit rate: 60-90% after warmup\n",
    "- Quality score: 0.7-0.95 depending on domain\n",
    "\n",
    "### 🔗 Resources:\n",
    "- [PageIndex Documentation](https://docs.pageindex.ai/)\n",
    "- [LangGraph Documentation](https://python.langchain.com/docs/langgraph)\n",
    "- [Brave Search API](https://brave.com/search-api/)\n",
    "- [Braintrust Documentation](https://docs.braintrust.dev/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}