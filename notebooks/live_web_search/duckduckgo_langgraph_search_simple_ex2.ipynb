{
 "cells": [
  {
      "cell_type": "markdown",
      "id": "6a44f011",
      "metadata": {
        "id": "6a44f011"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimitarpg13/agentic_architectures_and_design_patterns/blob/main/notebooks/live_web_search/duckduckgo_langgraph_search_simple_ex2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
  },
  {
   "cell_type": "markdown",
   "id": "f9001948",
   "metadata": {},
   "source": [
    "\n",
    "# DuckDuckGo + LangGraph: Live Web Search (Jupyter Notebook)\n",
    "\n",
    "This notebook shows how to wire **DuckDuckGo** search into a minimal **LangGraph** app for live web lookups.\n",
    "- No API key needed for search (uses the `duckduckgo-search` package).\n",
    "- Summarization step works without an LLM by default (rule-based), and **optionally** uses OpenAI if you have `OPENAI_API_KEY` set.\n",
    "\n",
    "> Tested with Python 3.10+.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbb785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you're running this on a fresh environment, uncomment and run:\n",
    "%pip install -q duckduckgo-search langgraph langchain-core langchain-community openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import TypedDict, List, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "# LangGraph core\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# DuckDuckGo search\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "# Optional OpenAI summarization\n",
    "import os\n",
    "OPENAI_AVAILABLE = False\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "    # A quick capability check; won't throw if no key, but calls will later\n",
    "    OPENAI_AVAILABLE = True if os.getenv(\"OPENAI_API_KEY\") else False\n",
    "except Exception:\n",
    "    OPENAI_AVAILABLE = False\n",
    "\n",
    "# Small utilities\n",
    "def _now_iso():\n",
    "    return datetime.now().isoformat(timespec=\"seconds\")\n",
    "\n",
    "print(\"OpenAI available:\", OPENAI_AVAILABLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbbc7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SearchState(TypedDict, total=False):\n",
    "    # Input\n",
    "    query: str\n",
    "    # Intermediate\n",
    "    results: List[Dict]\n",
    "    # Output\n",
    "    answer_markdown: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f467f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_node(state: SearchState) -> SearchState:\n",
    "    query = state.get(\"query\", \"\").strip()\n",
    "    if not query:\n",
    "        raise ValueError(\"Empty query. Provide a non-empty 'query' in the state.\")\n",
    "    \n",
    "    max_results = 8  # tweak as desired\n",
    "    results: List[Dict] = []\n",
    "    with DDGS() as ddgs:\n",
    "        for r in ddgs.text(query, max_results=max_results, safesearch=\"moderate\", region=\"wt-wt\"):\n",
    "            # r typically has keys like: title, href, body\n",
    "            results.append({\n",
    "                \"title\": r.get(\"title\"),\n",
    "                \"link\": r.get(\"href\"),\n",
    "                \"snippet\": r.get(\"body\"),\n",
    "            })\n",
    "    return {\"results\": results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _markdown_from_results(results: List[Dict], query: str) -> str:\n",
    "    if not results:\n",
    "        return f\"**No results found** for: `{query}`\"\n",
    "    \n",
    "    lines = [f\"### Top DuckDuckGo hits for: `{query}` (_{_now_iso()}_)\\n\"]\n",
    "    for i, r in enumerate(results, 1):\n",
    "        title = r.get(\"title\") or \"Untitled\"\n",
    "        link = r.get(\"link\") or \"\"\n",
    "        snippet = r.get(\"snippet\") or \"\"\n",
    "        lines.append(f\"{i}. [{title}]({link})\\n   - {snippet}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def _summarize_with_openai(results: List[Dict], query: str) -> Optional[str]:\n",
    "    if not OPENAI_AVAILABLE:\n",
    "        return None\n",
    "    try:\n",
    "        # Compose a compact prompt\n",
    "        bullets = \"\\n\".join([f\"- {r.get('title')} â€” {r.get('snippet')}\" for r in results[:8]])\n",
    "        prompt = f\"\"\"You are a helpful research assistant.\n",
    "Summarize the most relevant findings below for the user query: \"{query}\".\n",
    "Keep it concise (5-8 bullet points) and avoid redundancy. Include key facts and dates if present.\n",
    "\n",
    "Findings:\n",
    "{bullets}\n",
    "\"\"\"\n",
    "        # Using the OpenAI \"Responses\" API for simplicity if available.\n",
    "        resp = client.responses.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            input=prompt,\n",
    "        )\n",
    "        # Extract text\n",
    "        parts = []\n",
    "        for out in resp.output:\n",
    "            if out.type == \"message\":\n",
    "                for c in out.message.content:\n",
    "                    if c.type == \"text\":\n",
    "                        parts.append(c.text)\n",
    "        text = \"\\n\".join(parts).strip()\n",
    "        if text:\n",
    "            return \"### Summary\\n\" + text\n",
    "    except Exception as e:\n",
    "        print(\"OpenAI summarize failed:\", e)\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def summarize_node(state: SearchState) -> SearchState:\n",
    "    results = state.get(\"results\", [])\n",
    "    query = state.get(\"query\", \"\")\n",
    "    \n",
    "    # Always include a markdown list of results.\n",
    "    md = _markdown_from_results(results, query)\n",
    "    \n",
    "    # Optionally append an OpenAI-generated summary if available.\n",
    "    summary = _summarize_with_openai(results, query)\n",
    "    if summary:\n",
    "        md = summary + \"\\n\\n\" + md\n",
    "    \n",
    "    return {\"answer_markdown\": md}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph = StateGraph(SearchState)\n",
    "graph.add_node(\"search\", search_node)\n",
    "graph.add_node(\"summarize\", summarize_node)\n",
    "\n",
    "graph.set_entry_point(\"search\")\n",
    "graph.add_edge(\"search\", \"summarize\")\n",
    "graph.add_edge(\"summarize\", END)\n",
    "\n",
    "# Optional in-memory checkpointer\n",
    "memory = MemorySaver()\n",
    "app = graph.compile(checkpointer=memory)\n",
    "\n",
    "print(\"Graph ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7f8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_query(query: str) -> SearchState:\n",
    "    initial: SearchState = {\"query\": query}\n",
    "    final_state = app.invoke(initial)\n",
    "    return final_state\n",
    "\n",
    "# Example\n",
    "example_query = \"LangGraph documentation and examples for building search tools with DuckDuckGo\"\n",
    "final = run_query(example_query)\n",
    "final.keys(), print(final.get(\"answer_markdown\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c0bede",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run multiple queries without reloading the kernel.\n",
    "# Stop with KeyboardInterrupt or by not entering a query.\n",
    "try:\n",
    "    while True:\n",
    "        q = input(\"\\nEnter a query (or press Enter to stop): \").strip()\n",
    "        if not q:\n",
    "            break\n",
    "        st = run_query(q)\n",
    "        print(\"\\n\" + st.get(\"answer_markdown\", \"\"))\n",
    "except KeyboardInterrupt:\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
