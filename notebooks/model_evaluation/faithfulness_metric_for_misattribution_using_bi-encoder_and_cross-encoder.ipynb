{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Misattribution Detection with MLflow Faithfulness Metrics\n",
        "\n",
        "This notebook demonstrates how to use MLflow faithfulness metrics to detect **misattribution** in LLM outputs. Misattribution occurs when the model incorrectly assigns facts, actions, quotes, or accomplishments to the wrong entity.\n",
        "\n",
        "## What is Misattribution?\n",
        "\n",
        "Misattribution is a specific type of hallucination where:\n",
        "- **Actions are assigned to wrong actors** (e.g., \"Einstein invented the telephone\")\n",
        "- **Quotes are attributed to wrong people** (e.g., \"Shakespeare said 'I have a dream'\")\n",
        "- **Accomplishments are credited to wrong entities** (e.g., \"Microsoft created the iPhone\")\n",
        "- **Properties are associated with wrong subjects** (e.g., \"The Nile is in South America\")\n",
        "\n",
        "### Why Misattribution Matters:\n",
        "| Impact | Example |\n",
        "|--------|---------|\n",
        "| **Misinformation** | Crediting wrong inventor spreads false history |\n",
        "| **Legal Issues** | Wrong company attribution can cause disputes |\n",
        "| **Credibility Loss** | Users lose trust in AI systems |\n",
        "| **Harmful Decisions** | Wrong medical/legal attribution can cause harm |\n",
        "\n",
        "### Faithfulness Score for Misattribution:\n",
        "| Score Range | Interpretation | Action |\n",
        "|-------------|----------------|--------|\n",
        "| >= 0.70 | Correct Attribution | Safe |\n",
        "| 0.50 - 0.70 | Possible Issues | Review |\n",
        "| 0.30 - 0.50 | Likely Misattribution | Flag |\n",
        "| < 0.30 | Clear Misattribution | Block |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q mlflow sentence-transformers pandas numpy scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%restart_python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from typing import List, Dict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print(\"‚úÖ Libraries loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Misattribution Detector\n",
        "\n",
        "We use the same faithfulness metrics as hallucination detection, but focus specifically on entity-fact relationships. The NLI model is particularly effective at detecting when facts are attributed to wrong entities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MisattributionDetector:\n",
        "    \"\"\"\n",
        "    Detects misattribution errors where facts, actions, or quotes are \n",
        "    incorrectly attributed to wrong entities.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, \n",
        "                 embedding_model: str = \"all-MiniLM-L6-v2\",\n",
        "                 nli_model: str = \"cross-encoder/nli-deberta-v3-small\"):\n",
        "        \"\"\"Initialize with embedding and NLI models.\"\"\"\n",
        "        print(f\"Loading embedding model: {embedding_model}...\")\n",
        "        self.embedding_model = SentenceTransformer(embedding_model)\n",
        "        \n",
        "        print(f\"Loading NLI model: {nli_model}...\")\n",
        "        self.nli_model = CrossEncoder(nli_model)\n",
        "        \n",
        "        print(\"‚úÖ Misattribution detector ready!\")\n",
        "\n",
        "    def compute_semantic_faithfulness(self, answer: str, context: str) -> float:\n",
        "        \"\"\"Compute faithfulness using semantic similarity.\"\"\"\n",
        "        answer_embedding = self.embedding_model.encode([answer])[0]\n",
        "        context_embedding = self.embedding_model.encode([context])[0]\n",
        "        similarity = cosine_similarity([answer_embedding], [context_embedding])[0][0]\n",
        "        return max(0, min(1, (similarity + 1) / 2))\n",
        "\n",
        "    def compute_nli_faithfulness(self, answer: str, context: str) -> float:\n",
        "        \"\"\"Compute faithfulness using NLI entailment.\"\"\"\n",
        "        scores = self.nli_model.predict([(context, answer)])[0]\n",
        "        if isinstance(scores, (int, float)):\n",
        "            return 1 / (1 + np.exp(-scores))  # sigmoid\n",
        "        return float(scores[2])  # entailment score\n",
        "\n",
        "    def compute_token_overlap(self, answer: str, context: str) -> float:\n",
        "        \"\"\"Compute simple token overlap faithfulness.\"\"\"\n",
        "        stop_words = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', \n",
        "                      'to', 'of', 'in', 'for', 'on', 'with', 'at', 'by', 'from',\n",
        "                      'and', 'but', 'or', 'it', 'its', 'this', 'that', 'who'}\n",
        "        \n",
        "        answer_tokens = set(answer.lower().split()) - stop_words\n",
        "        context_tokens = set(context.lower().split()) - stop_words\n",
        "        \n",
        "        if not answer_tokens:\n",
        "            return 1.0\n",
        "        \n",
        "        overlap = answer_tokens.intersection(context_tokens)\n",
        "        return len(overlap) / len(answer_tokens)\n",
        "\n",
        "    def detect_misattribution(self, answer: str, context: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Detect if an answer contains misattribution.\n",
        "        \n",
        "        Returns:\n",
        "            Dictionary with scores and misattribution verdict\n",
        "        \"\"\"\n",
        "        semantic = self.compute_semantic_faithfulness(answer, context)\n",
        "        nli = self.compute_nli_faithfulness(answer, context)\n",
        "        overlap = self.compute_token_overlap(answer, context)\n",
        "        \n",
        "        # Combined score (NLI weighted heavily for attribution detection)\n",
        "        combined = 0.55 * nli + 0.30 * semantic + 0.15 * overlap\n",
        "        \n",
        "        # Determine misattribution category\n",
        "        if combined >= 0.70:\n",
        "            category = \"‚úÖ Correct Attribution\"\n",
        "            is_misattribution = False\n",
        "            risk = \"Low\"\n",
        "        elif combined >= 0.50:\n",
        "            category = \"‚ö†Ô∏è Possible Misattribution\"\n",
        "            is_misattribution = True\n",
        "            risk = \"Medium\"\n",
        "        elif combined >= 0.30:\n",
        "            category = \"‚ùå Likely Misattribution\"\n",
        "            is_misattribution = True\n",
        "            risk = \"High\"\n",
        "        else:\n",
        "            category = \"üö´ Clear Misattribution\"\n",
        "            is_misattribution = True\n",
        "            risk = \"Critical\"\n",
        "        \n",
        "        return {\n",
        "            \"semantic_score\": semantic,\n",
        "            \"nli_score\": nli,\n",
        "            \"overlap_score\": overlap,\n",
        "            \"combined_score\": combined,\n",
        "            \"category\": category,\n",
        "            \"is_misattribution\": is_misattribution,\n",
        "            \"risk_level\": risk\n",
        "        }\n",
        "\n",
        "# Initialize the detector\n",
        "detector = MisattributionDetector()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test Examples: Detecting Misattributions\n",
        "\n",
        "We'll test several categories of misattribution:\n",
        "1. **Inventor/Discovery Misattribution** - Wrong person credited for inventions\n",
        "2. **Quote Misattribution** - Quotes assigned to wrong speakers\n",
        "3. **Company/Product Misattribution** - Products credited to wrong companies\n",
        "4. **Historical Event Misattribution** - Events attributed to wrong actors\n",
        "5. **Geographic Misattribution** - Locations associated with wrong places\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define test examples with context, correct answer, and misattributed answer\n",
        "test_examples = [\n",
        "    {\n",
        "        \"name\": \"Example 1: Inventor Misattribution\",\n",
        "        \"category\": \"Invention\",\n",
        "        \"context\": \"Thomas Edison invented the practical incandescent light bulb in 1879. He conducted thousands of experiments at his Menlo Park laboratory before achieving success.\",\n",
        "        \"correct_answer\": \"Thomas Edison invented the practical incandescent light bulb in 1879 after thousands of experiments at Menlo Park.\",\n",
        "        \"misattributed_answer\": \"Nikola Tesla invented the practical incandescent light bulb in 1879 after thousands of experiments at Menlo Park.\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Example 2: Quote Misattribution\",\n",
        "        \"category\": \"Quote\",\n",
        "        \"context\": \"Martin Luther King Jr. delivered his famous 'I Have a Dream' speech during the March on Washington in 1963. The speech became a defining moment of the civil rights movement.\",\n",
        "        \"correct_answer\": \"Martin Luther King Jr. gave the 'I Have a Dream' speech during the 1963 March on Washington.\",\n",
        "        \"misattributed_answer\": \"Abraham Lincoln gave the 'I Have a Dream' speech during the 1963 March on Washington.\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Example 3: Company/Product Misattribution\",\n",
        "        \"category\": \"Company\",\n",
        "        \"context\": \"Apple Inc. introduced the iPhone in 2007. Steve Jobs unveiled the revolutionary smartphone at the Macworld Conference, describing it as three products in one.\",\n",
        "        \"correct_answer\": \"Apple and Steve Jobs introduced the iPhone at Macworld in 2007, calling it three products in one.\",\n",
        "        \"misattributed_answer\": \"Microsoft and Bill Gates introduced the iPhone at Macworld in 2007, calling it three products in one.\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Example 4: Scientific Discovery Misattribution\",\n",
        "        \"category\": \"Discovery\",\n",
        "        \"context\": \"Marie Curie discovered polonium and radium. She won two Nobel Prizes: one in Physics (1903) and one in Chemistry (1911), becoming the first person to win Nobel Prizes in two different sciences.\",\n",
        "        \"correct_answer\": \"Marie Curie discovered polonium and radium, winning Nobel Prizes in both Physics and Chemistry.\",\n",
        "        \"misattributed_answer\": \"Albert Einstein discovered polonium and radium, winning Nobel Prizes in both Physics and Chemistry.\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Example 5: Historical Event Misattribution\",\n",
        "        \"category\": \"History\",\n",
        "        \"context\": \"Neil Armstrong became the first human to walk on the Moon on July 20, 1969. He spoke the famous words 'That's one small step for man, one giant leap for mankind' as he stepped onto the lunar surface.\",\n",
        "        \"correct_answer\": \"Neil Armstrong was the first person to walk on the Moon in 1969, saying 'one small step for man, one giant leap for mankind.'\",\n",
        "        \"misattributed_answer\": \"Buzz Aldrin was the first person to walk on the Moon in 1969, saying 'one small step for man, one giant leap for mankind.'\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Example 6: Geographic Misattribution\",\n",
        "        \"category\": \"Geography\",\n",
        "        \"context\": \"The Amazon River, located in South America, is the largest river by discharge volume. It flows through Brazil, Peru, and Colombia, and its basin contains the world's largest rainforest.\",\n",
        "        \"correct_answer\": \"The Amazon River is in South America, flowing through Brazil, Peru, and Colombia with the world's largest rainforest.\",\n",
        "        \"misattributed_answer\": \"The Amazon River is in Africa, flowing through Nigeria, Congo, and Egypt with the world's largest rainforest.\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Example 7: Author Misattribution\",\n",
        "        \"category\": \"Literature\",\n",
        "        \"context\": \"William Shakespeare wrote Romeo and Juliet around 1594-1596. The tragic love story has become one of the most performed plays in history and influenced countless adaptations.\",\n",
        "        \"correct_answer\": \"William Shakespeare wrote Romeo and Juliet in the 1590s, creating one of history's most performed plays.\",\n",
        "        \"misattributed_answer\": \"Charles Dickens wrote Romeo and Juliet in the 1590s, creating one of history's most performed plays.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"üìã Loaded {len(test_examples)} misattribution test examples across {len(set(e['category'] for e in test_examples))} categories\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Running Misattribution Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_detection_result(name: str, category: str, context: str, answer: str, result: Dict, answer_type: str):\n",
        "    \"\"\"Pretty print the misattribution detection result.\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"üìù {name}\")\n",
        "    print(f\"   Category: {category} | Type: {answer_type}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"\\nüìÑ Context: {context[:100]}...\")\n",
        "    print(f\"\\nüí¨ Answer: {answer}\")\n",
        "    print(f\"\\nüìä SCORES:\")\n",
        "    print(f\"   ‚Ä¢ Semantic Similarity: {result['semantic_score']:.3f}\")\n",
        "    print(f\"   ‚Ä¢ NLI Entailment:      {result['nli_score']:.3f}\")\n",
        "    print(f\"   ‚Ä¢ Token Overlap:       {result['overlap_score']:.3f}\")\n",
        "    print(f\"   ‚Ä¢ Combined Score:      {result['combined_score']:.3f}\")\n",
        "    print(f\"\\nüéØ VERDICT: {result['category']}\")\n",
        "    print(f\"   ‚Ä¢ Is Misattribution: {'YES ‚ùå' if result['is_misattribution'] else 'NO ‚úì'}\")\n",
        "    print(f\"   ‚Ä¢ Risk Level: {result['risk_level']}\")\n",
        "\n",
        "# Run detection on all examples\n",
        "print(\"üîç MISATTRIBUTION DETECTION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for example in test_examples:\n",
        "    # Test correct attribution\n",
        "    correct_result = detector.detect_misattribution(\n",
        "        example[\"correct_answer\"], \n",
        "        example[\"context\"]\n",
        "    )\n",
        "    print_detection_result(\n",
        "        example[\"name\"], \n",
        "        example[\"category\"],\n",
        "        example[\"context\"], \n",
        "        example[\"correct_answer\"], \n",
        "        correct_result, \n",
        "        \"CORRECT ATTRIBUTION\"\n",
        "    )\n",
        "    all_results.append({\n",
        "        \"example\": example[\"name\"],\n",
        "        \"category\": example[\"category\"],\n",
        "        \"type\": \"Correct\",\n",
        "        \"combined_score\": correct_result[\"combined_score\"],\n",
        "        \"is_misattribution\": correct_result[\"is_misattribution\"],\n",
        "        \"verdict\": correct_result[\"category\"]\n",
        "    })\n",
        "    \n",
        "    # Test misattributed answer\n",
        "    misattributed_result = detector.detect_misattribution(\n",
        "        example[\"misattributed_answer\"], \n",
        "        example[\"context\"]\n",
        "    )\n",
        "    print_detection_result(\n",
        "        example[\"name\"], \n",
        "        example[\"category\"],\n",
        "        example[\"context\"], \n",
        "        example[\"misattributed_answer\"], \n",
        "        misattributed_result, \n",
        "        \"MISATTRIBUTED ANSWER\"\n",
        "    )\n",
        "    all_results.append({\n",
        "        \"example\": example[\"name\"],\n",
        "        \"category\": example[\"category\"],\n",
        "        \"type\": \"Misattributed\",\n",
        "        \"combined_score\": misattributed_result[\"combined_score\"],\n",
        "        \"is_misattribution\": misattributed_result[\"is_misattribution\"],\n",
        "        \"verdict\": misattributed_result[\"category\"]\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Summary Results Table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create summary DataFrame\n",
        "results_df = pd.DataFrame(all_results)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä SUMMARY: MISATTRIBUTION DETECTION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Format the dataframe for display\n",
        "display_df = results_df.copy()\n",
        "display_df[\"combined_score\"] = display_df[\"combined_score\"].apply(lambda x: f\"{x:.3f}\")\n",
        "display_df[\"is_misattribution\"] = display_df[\"is_misattribution\"].apply(lambda x: \"‚ùå YES\" if x else \"‚úì NO\")\n",
        "display_df.columns = [\"Example\", \"Category\", \"Answer Type\", \"Score\", \"Misattribution?\", \"Verdict\"]\n",
        "\n",
        "print(\"\\n\")\n",
        "print(display_df.to_string(index=False))\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_identified = sum(1 for r in all_results if r[\"type\"] == \"Correct\" and not r[\"is_misattribution\"])\n",
        "misattributed_detected = sum(1 for r in all_results if r[\"type\"] == \"Misattributed\" and r[\"is_misattribution\"])\n",
        "total = len(test_examples)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"üìà DETECTION ACCURACY\")\n",
        "print(\"=\"*80)\n",
        "print(f\"   ‚Ä¢ Correct attributions identified:     {correct_identified}/{total} ({correct_identified/total*100:.0f}%)\")\n",
        "print(f\"   ‚Ä¢ Misattributions detected:            {misattributed_detected}/{total} ({misattributed_detected/total*100:.0f}%)\")\n",
        "print(f\"   ‚Ä¢ Overall accuracy:                    {(correct_identified+misattributed_detected)/(total*2)*100:.0f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Analysis by Misattribution Category\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze by category\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä ANALYSIS BY MISATTRIBUTION CATEGORY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "categories = results_df[\"category\"].unique()\n",
        "\n",
        "for cat in categories:\n",
        "    cat_results = results_df[results_df[\"category\"] == cat]\n",
        "    correct_score = cat_results[cat_results[\"type\"] == \"Correct\"][\"combined_score\"].values[0]\n",
        "    misattr_score = cat_results[cat_results[\"type\"] == \"Misattributed\"][\"combined_score\"].values[0]\n",
        "    score_gap = correct_score - misattr_score\n",
        "    \n",
        "    print(f\"\\nüìå {cat}:\")\n",
        "    print(f\"   Correct Attribution Score:     {correct_score:.3f}\")\n",
        "    print(f\"   Misattributed Score:           {misattr_score:.3f}\")\n",
        "    print(f\"   Detection Gap:                 {score_gap:.3f} {'‚úì' if score_gap > 0.15 else '‚ö†Ô∏è'}\")\n",
        "    \n",
        "# Overall statistics\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"üìä OVERALL STATISTICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "correct_scores = results_df[results_df[\"type\"] == \"Correct\"][\"combined_score\"]\n",
        "misattr_scores = results_df[results_df[\"type\"] == \"Misattributed\"][\"combined_score\"]\n",
        "\n",
        "print(f\"\\nüìó CORRECT ATTRIBUTION SCORES:\")\n",
        "print(f\"   Mean:  {correct_scores.mean():.3f}\")\n",
        "print(f\"   Min:   {correct_scores.min():.3f}\")\n",
        "print(f\"   Max:   {correct_scores.max():.3f}\")\n",
        "\n",
        "print(f\"\\nüìï MISATTRIBUTED SCORES:\")\n",
        "print(f\"   Mean:  {misattr_scores.mean():.3f}\")\n",
        "print(f\"   Min:   {misattr_scores.min():.3f}\")\n",
        "print(f\"   Max:   {misattr_scores.max():.3f}\")\n",
        "\n",
        "print(f\"\\nüìâ SEPARATION:\")\n",
        "avg_gap = correct_scores.mean() - misattr_scores.mean()\n",
        "print(f\"   Average Gap: {avg_gap:.3f}\")\n",
        "print(f\"   Overlap Risk: {'Low ‚úì' if avg_gap > 0.25 else 'Medium ‚ö†Ô∏è' if avg_gap > 0.15 else 'High ‚ùå'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Interactive Testing: Try Your Own Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_misattribution(context: str, answer: str):\n",
        "    \"\"\"\n",
        "    Test if an answer contains misattribution given a context.\n",
        "    \n",
        "    Usage:\n",
        "        test_misattribution(\n",
        "            context=\"Albert Einstein developed the theory of relativity.\",\n",
        "            answer=\"Einstein developed the theory of relativity.\"\n",
        "        )\n",
        "    \"\"\"\n",
        "    result = detector.detect_misattribution(answer, context)\n",
        "    \n",
        "    print(\"=\"*60)\n",
        "    print(\"üîç MISATTRIBUTION TEST\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nüìÑ Context:\\n{context}\")\n",
        "    print(f\"\\nüí¨ Answer:\\n{answer}\")\n",
        "    print(f\"\\nüìä SCORES:\")\n",
        "    print(f\"   ‚Ä¢ Semantic: {result['semantic_score']:.3f}\")\n",
        "    print(f\"   ‚Ä¢ NLI:      {result['nli_score']:.3f}\")\n",
        "    print(f\"   ‚Ä¢ Overlap:  {result['overlap_score']:.3f}\")\n",
        "    print(f\"   ‚Ä¢ Combined: {result['combined_score']:.3f}\")\n",
        "    print(f\"\\nüéØ RESULT: {result['category']}\")\n",
        "    print(f\"   Risk Level: {result['risk_level']}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Example: Correct attribution\n",
        "print(\"TEST 1: Correct Attribution\")\n",
        "test_misattribution(\n",
        "    context=\"Isaac Newton formulated the laws of motion and universal gravitation in his work Principia Mathematica published in 1687.\",\n",
        "    answer=\"Isaac Newton developed the laws of motion and universal gravitation in Principia Mathematica (1687).\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Misattribution (wrong person)\n",
        "print(\"TEST 2: Misattribution - Wrong Person\")\n",
        "test_misattribution(\n",
        "    context=\"Isaac Newton formulated the laws of motion and universal gravitation in his work Principia Mathematica published in 1687.\",\n",
        "    answer=\"Galileo Galilei developed the laws of motion and universal gravitation in Principia Mathematica (1687).\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Misattribution (wrong company)\n",
        "print(\"TEST 3: Misattribution - Wrong Company\")\n",
        "test_misattribution(\n",
        "    context=\"Google developed the Android operating system. Android was first released in 2008 and has become the world's most widely used smartphone platform.\",\n",
        "    answer=\"Samsung developed the Android operating system, first released in 2008 as the world's most widely used smartphone platform.\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Understanding Misattribution Detection Challenges\n",
        "\n",
        "Misattribution is particularly tricky because the answer often contains factually correct information - just attributed to the wrong entity. This creates high semantic overlap but should still be flagged.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate the challenge: High semantic overlap but wrong attribution\n",
        "print(\"=\"*70)\n",
        "print(\"üî¨ CHALLENGE CASE: HIGH OVERLAP, WRONG ENTITY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "challenge_context = \"\"\"\n",
        "Jeff Bezos founded Amazon in 1994 as an online bookstore in his garage \n",
        "in Bellevue, Washington. The company later expanded to sell everything \n",
        "and became one of the world's most valuable companies.\n",
        "\"\"\"\n",
        "\n",
        "correct_answer = \"Jeff Bezos founded Amazon in 1994 as an online bookstore, which grew to become one of the most valuable companies.\"\n",
        "misattributed_answer = \"Elon Musk founded Amazon in 1994 as an online bookstore, which grew to become one of the most valuable companies.\"\n",
        "\n",
        "print(\"\\nüìÑ Context:\", challenge_context.strip())\n",
        "print(\"\\n--- Testing Correct Attribution ---\")\n",
        "correct_result = detector.detect_misattribution(correct_answer, challenge_context)\n",
        "print(f\"üí¨ Answer: {correct_answer}\")\n",
        "print(f\"üìä Scores: Semantic={correct_result['semantic_score']:.3f}, NLI={correct_result['nli_score']:.3f}, Overlap={correct_result['overlap_score']:.3f}\")\n",
        "print(f\"üéØ Combined: {correct_result['combined_score']:.3f} ‚Üí {correct_result['category']}\")\n",
        "\n",
        "print(\"\\n--- Testing Misattributed Answer ---\")\n",
        "misattr_result = detector.detect_misattribution(misattributed_answer, challenge_context)\n",
        "print(f\"üí¨ Answer: {misattributed_answer}\")\n",
        "print(f\"üìä Scores: Semantic={misattr_result['semantic_score']:.3f}, NLI={misattr_result['nli_score']:.3f}, Overlap={misattr_result['overlap_score']:.3f}\")\n",
        "print(f\"üéØ Combined: {misattr_result['combined_score']:.3f} ‚Üí {misattr_result['category']}\")\n",
        "\n",
        "print(\"\\nüìå KEY INSIGHT:\")\n",
        "print(f\"   Both answers share similar structure and high word overlap.\")\n",
        "print(f\"   However, the NLI model detects the entity mismatch:\")\n",
        "print(f\"   ‚Ä¢ NLI score difference: {correct_result['nli_score'] - misattr_result['nli_score']:.3f}\")\n",
        "print(f\"   ‚Ä¢ This is why NLI is weighted heavily (55%) for misattribution detection.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Score Comparison Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visual comparison of scores\n",
        "correct_scores = results_df[results_df[\"type\"] == \"Correct\"][\"combined_score\"]\n",
        "misattr_scores = results_df[results_df[\"type\"] == \"Misattributed\"][\"combined_score\"]\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üìä SCORE COMPARISON: CORRECT vs MISATTRIBUTED\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nüìó CORRECT ATTRIBUTIONS:\")\n",
        "print(f\"   Average Score: {np.mean(correct_scores):.3f}\")\n",
        "print(f\"   Min Score:     {np.min(correct_scores):.3f}\")\n",
        "print(f\"   Max Score:     {np.max(correct_scores):.3f}\")\n",
        "\n",
        "print(\"\\nüìï MISATTRIBUTED ANSWERS:\")\n",
        "print(f\"   Average Score: {np.mean(misattr_scores):.3f}\")\n",
        "print(f\"   Min Score:     {np.min(misattr_scores):.3f}\")\n",
        "print(f\"   Max Score:     {np.max(misattr_scores):.3f}\")\n",
        "\n",
        "print(\"\\nüìâ SEPARATION METRICS:\")\n",
        "score_diff = np.mean(correct_scores) - np.mean(misattr_scores)\n",
        "print(f\"   Score Gap: {score_diff:.3f}\")\n",
        "\n",
        "# Visual bar representation\n",
        "print(\"\\nüìä VISUAL COMPARISON:\")\n",
        "print(f\"   Correct:      {'‚ñà' * int(np.mean(correct_scores) * 20):<20} {np.mean(correct_scores):.2f}\")\n",
        "print(f\"   Misattributed:{'‚ñà' * int(np.mean(misattr_scores) * 20):<20} {np.mean(misattr_scores):.2f}\")\n",
        "print(f\"   Threshold:    {'‚îÄ' * 10}‚îÇ{'‚îÄ' * 9}  0.50 (misattribution cutoff)\")\n",
        "\n",
        "# Per-category visualization\n",
        "print(\"\\nüìä BY CATEGORY:\")\n",
        "for cat in categories:\n",
        "    cat_data = results_df[results_df[\"category\"] == cat]\n",
        "    c_score = cat_data[cat_data[\"type\"] == \"Correct\"][\"combined_score\"].values[0]\n",
        "    m_score = cat_data[cat_data[\"type\"] == \"Misattributed\"][\"combined_score\"].values[0]\n",
        "    print(f\"   {cat:12} Correct: {'‚ñà' * int(c_score * 15):<15} {c_score:.2f}  |  Misattr: {'‚ñà' * int(m_score * 15):<15} {m_score:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Key Takeaways\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\"\"\n",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "‚ïë                    KEY TAKEAWAYS: MISATTRIBUTION DETECTION                   ‚ïë\n",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "‚úÖ WHAT WE DEMONSTRATED:\n",
        "\n",
        "1. MISATTRIBUTION TYPES DETECTED:\n",
        "   ‚Ä¢ Inventor/Discovery attribution errors\n",
        "   ‚Ä¢ Quote misattribution (wrong speaker)\n",
        "   ‚Ä¢ Company/Product attribution errors\n",
        "   ‚Ä¢ Historical event misattribution\n",
        "   ‚Ä¢ Geographic location errors\n",
        "   ‚Ä¢ Author/Creator misattribution\n",
        "\n",
        "2. WHY NLI IS CRITICAL:\n",
        "   ‚Ä¢ Semantic similarity alone fails for misattribution\n",
        "   ‚Ä¢ Both correct and wrong attributions have high word overlap\n",
        "   ‚Ä¢ NLI detects entailment violations when entities mismatch\n",
        "   ‚Ä¢ Weighted 55% in combined score for this reason\n",
        "\n",
        "3. DETECTION CHALLENGES:\n",
        "   ‚Ä¢ High semantic similarity between correct and wrong answers\n",
        "   ‚Ä¢ Token overlap is nearly identical\n",
        "   ‚Ä¢ Only entity names differ - requires understanding of context\n",
        "   ‚Ä¢ NLI models excel at catching these contradictions\n",
        "\n",
        "4. RECOMMENDED THRESHOLDS FOR MISATTRIBUTION:\n",
        "   ‚Ä¢ >= 0.70: Safe - correct attribution\n",
        "   ‚Ä¢ 0.50-0.70: Review - possible issues\n",
        "   ‚Ä¢ 0.30-0.50: Flag - likely misattribution\n",
        "   ‚Ä¢ < 0.30: Block - clear misattribution\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "üîó NEXT STEPS:\n",
        "   ‚Ä¢ Integrate with MLflow for production monitoring\n",
        "   ‚Ä¢ Set up entity-specific validation rules\n",
        "   ‚Ä¢ Combine with Named Entity Recognition (NER) for entity extraction\n",
        "   ‚Ä¢ Build domain-specific attribution validators\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "‚ö†Ô∏è LIMITATIONS:\n",
        "   ‚Ä¢ Requires good NLI model understanding of entities\n",
        "   ‚Ä¢ May struggle with lesser-known entities\n",
        "   ‚Ä¢ Performance depends on context quality and completeness\n",
        "   ‚Ä¢ Consider ensemble approaches for high-stakes applications\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\"\"\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
