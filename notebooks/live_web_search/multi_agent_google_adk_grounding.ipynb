{
 "cells": [
  {
      "cell_type": "markdown",
      "id": "6a44f010",
      "metadata": {
        "id": "6a44f009"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimitarpg13/agentic_architectures_and_design_patterns/blob/main/notebooks/live_web_search/duckduckgo_langgraph_search_simple_ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Workflow with Google ADK and Search Grounding\n",
    "\n",
    "This notebook demonstrates a production-ready multi-agent system using Google's Agentic Development Kit (ADK) with Google Search for grounding responses in real-world data.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "- **Supervisor Agent**: Orchestrates the workflow and routes tasks\n",
    "- **Research Agent**: Performs web searches and gathers information\n",
    "- **Analysis Agent**: Analyzes and synthesizes research findings\n",
    "- **Writer Agent**: Generates final outputs based on analyzed data\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- Google Search integration for real-time grounding\n",
    "- State management with LangGraph\n",
    "- Error handling and retry logic\n",
    "- Structured output validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q google-genai langgraph langchain-google-genai langchain-google-community python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated, TypedDict, List, Dict, Any\n",
    "from enum import Enum\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Google ADK imports\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import Tool, FunctionDeclaration\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# LangChain imports for Google Search\n",
    "from langchain_google_community import GoogleSearchAPIWrapper\n",
    "from langchain.tools import Tool as LangChainTool\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Google API\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GOOGLE_CSE_ID = os.getenv(\"GOOGLE_CSE_ID\")  # Custom Search Engine ID\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"GOOGLE_API_KEY environment variable not set\")\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Agent State\n",
    "\n",
    "The shared state that all agents can access and modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"State shared across all agents in the workflow.\"\"\"\n",
    "    query: str\n",
    "    messages: List[Dict[str, str]]\n",
    "    search_results: List[Dict[str, Any]]\n",
    "    analysis: str\n",
    "    final_output: str\n",
    "    current_agent: str\n",
    "    next_agent: str\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "    errors: List[str]\n",
    "\n",
    "\n",
    "class AgentRole(str, Enum):\n",
    "    \"\"\"Enumeration of agent roles.\"\"\"\n",
    "    SUPERVISOR = \"supervisor\"\n",
    "    RESEARCHER = \"researcher\"\n",
    "    ANALYST = \"analyst\"\n",
    "    WRITER = \"writer\"\n",
    "    END = \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Google Search Tool Setup\n",
    "\n",
    "Configure Google Custom Search for grounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleSearchGrounding:\n",
    "    \"\"\"Google Search tool for grounding agent responses.\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, cse_id: str, num_results: int = 5):\n",
    "        self.api_key = api_key\n",
    "        self.cse_id = cse_id\n",
    "        self.num_results = num_results\n",
    "        \n",
    "        # Initialize Google Search wrapper\n",
    "        self.search_wrapper = GoogleSearchAPIWrapper(\n",
    "            google_api_key=api_key,\n",
    "            google_cse_id=cse_id,\n",
    "            k=num_results\n",
    "        )\n",
    "    \n",
    "    def search(self, query: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Execute search and return structured results.\"\"\"\n",
    "        try:\n",
    "            raw_results = self.search_wrapper.results(query, num_results=self.num_results)\n",
    "            \n",
    "            structured_results = []\n",
    "            for result in raw_results:\n",
    "                structured_results.append({\n",
    "                    \"title\": result.get(\"title\", \"\"),\n",
    "                    \"snippet\": result.get(\"snippet\", \"\"),\n",
    "                    \"link\": result.get(\"link\", \"\"),\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                })\n",
    "            \n",
    "            return structured_results\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Search error: {str(e)}\")\n",
    "            return [{\"error\": str(e)}]\n",
    "    \n",
    "    def format_results_for_context(self, results: List[Dict[str, Any]]) -> str:\n",
    "        \"\"\"Format search results for LLM context.\"\"\"\n",
    "        if not results or \"error\" in results[0]:\n",
    "            return \"No search results available.\"\n",
    "        \n",
    "        formatted = \"Search Results:\\n\\n\"\n",
    "        for i, result in enumerate(results, 1):\n",
    "            formatted += f\"{i}. {result['title']}\\n\"\n",
    "            formatted += f\"   {result['snippet']}\\n\"\n",
    "            formatted += f\"   Source: {result['link']}\\n\\n\"\n",
    "        \n",
    "        return formatted\n",
    "\n",
    "\n",
    "# Initialize search tool\n",
    "search_tool = GoogleSearchGrounding(\n",
    "    api_key=GOOGLE_API_KEY,\n",
    "    cse_id=GOOGLE_CSE_ID or \"demo-cse-id\",  # Use demo ID if not set\n",
    "    num_results=5\n",
    ")\n",
    "\n",
    "print(\"âœ“ Google Search tool initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Individual Agents\n",
    "\n",
    "Each agent has a specific role and uses Google's Gemini model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent:\n",
    "    \"\"\"Base class for all agents.\"\"\"\n",
    "    \n",
    "    def __init__(self, role: str, model_name: str = \"gemini-1.5-pro\"):\n",
    "        self.role = role\n",
    "        self.model = genai.GenerativeModel(model_name)\n",
    "    \n",
    "    def generate_response(self, prompt: str, temperature: float = 0.7) -> str:\n",
    "        \"\"\"Generate response using Gemini.\"\"\"\n",
    "        try:\n",
    "            response = self.model.generate_content(\n",
    "                prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature=temperature,\n",
    "                    max_output_tokens=2048,\n",
    "                )\n",
    "            )\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "\n",
    "\n",
    "class SupervisorAgent(BaseAgent):\n",
    "    \"\"\"Orchestrates the multi-agent workflow.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(AgentRole.SUPERVISOR)\n",
    "    \n",
    "    def route(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"Determine next agent based on current state.\"\"\"\n",
    "        \n",
    "        # Check iteration limit\n",
    "        if state[\"iteration\"] >= state[\"max_iterations\"]:\n",
    "            state[\"next_agent\"] = AgentRole.END\n",
    "            return state\n",
    "        \n",
    "        # Route based on current progress\n",
    "        if not state[\"search_results\"]:\n",
    "            state[\"next_agent\"] = AgentRole.RESEARCHER\n",
    "        elif not state[\"analysis\"]:\n",
    "            state[\"next_agent\"] = AgentRole.ANALYST\n",
    "        elif not state[\"final_output\"]:\n",
    "            state[\"next_agent\"] = AgentRole.WRITER\n",
    "        else:\n",
    "            state[\"next_agent\"] = AgentRole.END\n",
    "        \n",
    "        state[\"current_agent\"] = AgentRole.SUPERVISOR\n",
    "        state[\"iteration\"] += 1\n",
    "        \n",
    "        return state\n",
    "\n",
    "\n",
    "class ResearchAgent(BaseAgent):\n",
    "    \"\"\"Performs web searches and gathers information.\"\"\"\n",
    "    \n",
    "    def __init__(self, search_tool: GoogleSearchGrounding):\n",
    "        super().__init__(AgentRole.RESEARCHER)\n",
    "        self.search_tool = search_tool\n",
    "    \n",
    "    def research(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"Execute search queries and collect results.\"\"\"\n",
    "        \n",
    "        query = state[\"query\"]\n",
    "        \n",
    "        # Generate search query refinement using LLM\n",
    "        refinement_prompt = f\"\"\"\n",
    "You are a research agent. Given this user query: \"{query}\"\n",
    "\n",
    "Generate 2-3 specific search queries that will help gather comprehensive information.\n",
    "Format your response as a JSON array of strings.\n",
    "\n",
    "Example: [\"query 1\", \"query 2\", \"query 3\"]\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            refined_queries_text = self.generate_response(refinement_prompt, temperature=0.3)\n",
    "            # Parse JSON from response\n",
    "            refined_queries = json.loads(refined_queries_text)\n",
    "        except:\n",
    "            # Fallback to original query\n",
    "            refined_queries = [query]\n",
    "        \n",
    "        # Execute searches\n",
    "        all_results = []\n",
    "        for search_query in refined_queries:\n",
    "            results = self.search_tool.search(search_query)\n",
    "            all_results.extend(results)\n",
    "        \n",
    "        state[\"search_results\"] = all_results\n",
    "        state[\"current_agent\"] = AgentRole.RESEARCHER\n",
    "        state[\"messages\"].append({\n",
    "            \"agent\": AgentRole.RESEARCHER,\n",
    "            \"action\": \"search_completed\",\n",
    "            \"num_results\": len(all_results)\n",
    "        })\n",
    "        \n",
    "        return state\n",
    "\n",
    "\n",
    "class AnalysisAgent(BaseAgent):\n",
    "    \"\"\"Analyzes and synthesizes research findings.\"\"\"\n",
    "    \n",
    "    def __init__(self, search_tool: GoogleSearchGrounding):\n",
    "        super().__init__(AgentRole.ANALYST)\n",
    "        self.search_tool = search_tool\n",
    "    \n",
    "    def analyze(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"Analyze search results and extract insights.\"\"\"\n",
    "        \n",
    "        query = state[\"query\"]\n",
    "        search_context = self.search_tool.format_results_for_context(state[\"search_results\"])\n",
    "        \n",
    "        analysis_prompt = f\"\"\"\n",
    "You are an analysis agent. Your task is to analyze search results and extract key insights.\n",
    "\n",
    "User Query: {query}\n",
    "\n",
    "{search_context}\n",
    "\n",
    "Provide a comprehensive analysis that:\n",
    "1. Identifies key themes and patterns\n",
    "2. Highlights important facts and statistics\n",
    "3. Notes any contradictions or uncertainties\n",
    "4. Synthesizes information from multiple sources\n",
    "\n",
    "Format your analysis in clear, structured paragraphs.\n",
    "\"\"\"\n",
    "        \n",
    "        analysis = self.generate_response(analysis_prompt, temperature=0.5)\n",
    "        \n",
    "        state[\"analysis\"] = analysis\n",
    "        state[\"current_agent\"] = AgentRole.ANALYST\n",
    "        state[\"messages\"].append({\n",
    "            \"agent\": AgentRole.ANALYST,\n",
    "            \"action\": \"analysis_completed\",\n",
    "            \"analysis_length\": len(analysis)\n",
    "        })\n",
    "        \n",
    "        return state\n",
    "\n",
    "\n",
    "class WriterAgent(BaseAgent):\n",
    "    \"\"\"Generates final outputs based on analyzed data.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(AgentRole.WRITER)\n",
    "    \n",
    "    def write(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"Generate final response based on analysis.\"\"\"\n",
    "        \n",
    "        query = state[\"query\"]\n",
    "        analysis = state[\"analysis\"]\n",
    "        \n",
    "        writing_prompt = f\"\"\"\n",
    "You are a writer agent. Create a comprehensive, well-structured response to the user's query.\n",
    "\n",
    "User Query: {query}\n",
    "\n",
    "Analysis:\n",
    "{analysis}\n",
    "\n",
    "Generate a response that:\n",
    "1. Directly answers the user's query\n",
    "2. Is grounded in the analyzed information\n",
    "3. Is clear, accurate, and well-organized\n",
    "4. Cites sources where appropriate\n",
    "5. Acknowledges limitations or uncertainties\n",
    "\n",
    "Write in a professional yet accessible tone.\n",
    "\"\"\"\n",
    "        \n",
    "        final_output = self.generate_response(writing_prompt, temperature=0.6)\n",
    "        \n",
    "        state[\"final_output\"] = final_output\n",
    "        state[\"current_agent\"] = AgentRole.WRITER\n",
    "        state[\"messages\"].append({\n",
    "            \"agent\": AgentRole.WRITER,\n",
    "            \"action\": \"writing_completed\",\n",
    "            \"output_length\": len(final_output)\n",
    "        })\n",
    "        \n",
    "        return state\n",
    "\n",
    "\n",
    "print(\"âœ“ All agents defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Multi-Agent Workflow with LangGraph\n",
    "\n",
    "Orchestrate agents using a state graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgentWorkflow:\n",
    "    \"\"\"Multi-agent system orchestrator.\"\"\"\n",
    "    \n",
    "    def __init__(self, search_tool: GoogleSearchGrounding):\n",
    "        self.search_tool = search_tool\n",
    "        \n",
    "        # Initialize agents\n",
    "        self.supervisor = SupervisorAgent()\n",
    "        self.researcher = ResearchAgent(search_tool)\n",
    "        self.analyst = AnalysisAgent(search_tool)\n",
    "        self.writer = WriterAgent()\n",
    "        \n",
    "        # Build workflow graph\n",
    "        self.graph = self._build_graph()\n",
    "    \n",
    "    def _build_graph(self) -> StateGraph:\n",
    "        \"\"\"Construct the agent workflow graph.\"\"\"\n",
    "        \n",
    "        workflow = StateGraph(AgentState)\n",
    "        \n",
    "        # Add nodes\n",
    "        workflow.add_node(AgentRole.SUPERVISOR, self.supervisor.route)\n",
    "        workflow.add_node(AgentRole.RESEARCHER, self.researcher.research)\n",
    "        workflow.add_node(AgentRole.ANALYST, self.analyst.analyze)\n",
    "        workflow.add_node(AgentRole.WRITER, self.writer.write)\n",
    "        \n",
    "        # Define edges\n",
    "        workflow.set_entry_point(AgentRole.SUPERVISOR)\n",
    "        \n",
    "        # Conditional routing from supervisor\n",
    "        def route_from_supervisor(state: AgentState) -> str:\n",
    "            return state[\"next_agent\"]\n",
    "        \n",
    "        workflow.add_conditional_edges(\n",
    "            AgentRole.SUPERVISOR,\n",
    "            route_from_supervisor,\n",
    "            {\n",
    "                AgentRole.RESEARCHER: AgentRole.RESEARCHER,\n",
    "                AgentRole.ANALYST: AgentRole.ANALYST,\n",
    "                AgentRole.WRITER: AgentRole.WRITER,\n",
    "                AgentRole.END: END\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # All agents return to supervisor\n",
    "        workflow.add_edge(AgentRole.RESEARCHER, AgentRole.SUPERVISOR)\n",
    "        workflow.add_edge(AgentRole.ANALYST, AgentRole.SUPERVISOR)\n",
    "        workflow.add_edge(AgentRole.WRITER, AgentRole.SUPERVISOR)\n",
    "        \n",
    "        return workflow.compile()\n",
    "    \n",
    "    def run(self, query: str, max_iterations: int = 5) -> Dict[str, Any]:\n",
    "        \"\"\"Execute the multi-agent workflow.\"\"\"\n",
    "        \n",
    "        # Initialize state\n",
    "        initial_state: AgentState = {\n",
    "            \"query\": query,\n",
    "            \"messages\": [],\n",
    "            \"search_results\": [],\n",
    "            \"analysis\": \"\",\n",
    "            \"final_output\": \"\",\n",
    "            \"current_agent\": \"\",\n",
    "            \"next_agent\": \"\",\n",
    "            \"iteration\": 0,\n",
    "            \"max_iterations\": max_iterations,\n",
    "            \"errors\": []\n",
    "        }\n",
    "        \n",
    "        # Execute workflow\n",
    "        try:\n",
    "            final_state = self.graph.invoke(initial_state)\n",
    "            return final_state\n",
    "        except Exception as e:\n",
    "            print(f\"Workflow error: {str(e)}\")\n",
    "            initial_state[\"errors\"].append(str(e))\n",
    "            return initial_state\n",
    "    \n",
    "    def visualize_workflow(self):\n",
    "        \"\"\"Generate workflow visualization.\"\"\"\n",
    "        try:\n",
    "            from IPython.display import Image, display\n",
    "            display(Image(self.graph.get_graph().draw_mermaid_png()))\n",
    "        except Exception as e:\n",
    "            print(f\"Visualization not available: {str(e)}\")\n",
    "\n",
    "\n",
    "# Initialize workflow\n",
    "workflow = MultiAgentWorkflow(search_tool)\n",
    "print(\"âœ“ Multi-agent workflow initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Workflow (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the agent workflow graph\n",
    "workflow.visualize_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Execute Multi-Agent Workflow\n",
    "\n",
    "Run the workflow with a sample query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query\n",
    "query = \"What are the latest developments in quantum computing in 2025?\"\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"Starting multi-agent workflow...\\n\")\n",
    "\n",
    "# Run workflow\n",
    "result = workflow.run(query, max_iterations=5)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WORKFLOW EXECUTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nTotal iterations: {result['iteration']}\")\n",
    "print(f\"Number of search results: {len(result['search_results'])}\")\n",
    "print(f\"\\nAgent execution order:\")\n",
    "for msg in result['messages']:\n",
    "    print(f\"  - {msg['agent']}: {msg['action']}\")\n",
    "\n",
    "if result['errors']:\n",
    "    print(f\"\\nErrors encountered: {result['errors']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Display Detailed Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SEARCH RESULTS (Grounding Data)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, result in enumerate(result['search_results'][:5], 1):  # Show first 5\n",
    "    if 'error' not in result:\n",
    "        print(f\"\\n{i}. {result['title']}\")\n",
    "        print(f\"   {result['snippet']}\")\n",
    "        print(f\"   Source: {result['link']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{result['analysis']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL OUTPUT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{result['final_output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Features: Custom Tool Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom function for Gemini function calling\n",
    "search_function = FunctionDeclaration(\n",
    "    name=\"google_search\",\n",
    "    description=\"Search Google for current information to ground responses in real-world data\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The search query\"\n",
    "            },\n",
    "            \"num_results\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"Number of results to return\",\n",
    "                \"default\": 5\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create tool with function\n",
    "search_tool_for_gemini = Tool(function_declarations=[search_function])\n",
    "\n",
    "# Example: Using function calling with Gemini\n",
    "model_with_tools = genai.GenerativeModel(\n",
    "    \"gemini-1.5-pro\",\n",
    "    tools=[search_tool_for_gemini]\n",
    ")\n",
    "\n",
    "print(\"âœ“ Custom tool integration configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interactive Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_interactive_query(query: str):\n",
    "    \"\"\"Run workflow and display results in a formatted way.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing Query: {query}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    result = workflow.run(query)\n",
    "    \n",
    "    # Display in sections\n",
    "    print(\"\\nðŸ“Š WORKFLOW METRICS\")\n",
    "    print(f\"   Iterations: {result['iteration']}\")\n",
    "    print(f\"   Search Results: {len(result['search_results'])}\")\n",
    "    print(f\"   Analysis Length: {len(result['analysis'])} chars\")\n",
    "    print(f\"   Output Length: {len(result['final_output'])} chars\")\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ FINAL ANSWER\")\n",
    "    print(\"-\" * 80)\n",
    "    print(result['final_output'])\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Try different queries\n",
    "test_queries = [\n",
    "    \"What are the latest AI safety developments?\",\n",
    "    \"How is climate change affecting ocean temperatures?\",\n",
    "    \"What are the recent breakthroughs in fusion energy?\"\n",
    "]\n",
    "\n",
    "# Uncomment to run\n",
    "# for query in test_queries:\n",
    "#     result = run_interactive_query(query)\n",
    "#     print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Performance Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import List, Tuple\n",
    "\n",
    "def benchmark_workflow(queries: List[str]) -> List[Tuple[str, float, Dict]]:\n",
    "    \"\"\"Benchmark workflow performance across multiple queries.\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for query in queries:\n",
    "        start_time = time.time()\n",
    "        result = workflow.run(query)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        results.append((query, elapsed_time, result))\n",
    "        \n",
    "        print(f\"Query: {query[:50]}...\")\n",
    "        print(f\"Time: {elapsed_time:.2f}s\")\n",
    "        print(f\"Success: {bool(result['final_output'])}\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Example benchmark\n",
    "# benchmark_queries = [\n",
    "#     \"Latest in quantum computing\",\n",
    "#     \"Current state of renewable energy\",\n",
    "#     \"Advances in gene therapy\"\n",
    "# ]\n",
    "# benchmark_results = benchmark_workflow(benchmark_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Error Handling & Retry Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "import time\n",
    "\n",
    "def retry_with_backoff(max_retries: int = 3, backoff_factor: float = 2.0):\n",
    "    \"\"\"Decorator for retrying failed operations with exponential backoff.\"\"\"\n",
    "    \n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            retries = 0\n",
    "            while retries < max_retries:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    retries += 1\n",
    "                    if retries >= max_retries:\n",
    "                        raise\n",
    "                    wait_time = backoff_factor ** retries\n",
    "                    print(f\"Retry {retries}/{max_retries} after {wait_time}s delay: {str(e)}\")\n",
    "                    time.sleep(wait_time)\n",
    "            return None\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "class RobustMultiAgentWorkflow(MultiAgentWorkflow):\n",
    "    \"\"\"Enhanced workflow with error handling.\"\"\"\n",
    "    \n",
    "    @retry_with_backoff(max_retries=3)\n",
    "    def run(self, query: str, max_iterations: int = 5) -> Dict[str, Any]:\n",
    "        \"\"\"Execute workflow with retry logic.\"\"\"\n",
    "        return super().run(query, max_iterations)\n",
    "\n",
    "\n",
    "# Create robust workflow\n",
    "robust_workflow = RobustMultiAgentWorkflow(search_tool)\n",
    "print(\"âœ“ Robust workflow with error handling initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_workflow_results(result: Dict[str, Any], filename: str = None):\n",
    "    \"\"\"Save workflow results to JSON file.\"\"\"\n",
    "    \n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"workflow_results_{timestamp}.json\"\n",
    "    \n",
    "    # Create exportable version\n",
    "    export_data = {\n",
    "        \"query\": result[\"query\"],\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"iterations\": result[\"iteration\"],\n",
    "        \"search_results_count\": len(result[\"search_results\"]),\n",
    "        \"search_results\": result[\"search_results\"],\n",
    "        \"analysis\": result[\"analysis\"],\n",
    "        \"final_output\": result[\"final_output\"],\n",
    "        \"execution_log\": result[\"messages\"],\n",
    "        \"errors\": result[\"errors\"]\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(export_data, f, indent=2)\n",
    "    \n",
    "    print(f\"âœ“ Results saved to {filename}\")\n",
    "    return filename\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# if result and result['final_output']:\n",
    "#     save_workflow_results(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary & Next Steps\n",
    "\n",
    "### What We've Built\n",
    "\n",
    "1. **Multi-Agent System**: Supervisor, Researcher, Analyst, and Writer agents\n",
    "2. **Google Search Grounding**: Real-time search integration for up-to-date information\n",
    "3. **LangGraph Orchestration**: State management and workflow control\n",
    "4. **Error Handling**: Retry logic and robust error handling\n",
    "5. **Production Features**: Logging, monitoring, and result persistence\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Grounding**: All responses are grounded in real search results\n",
    "- **Multi-Step Reasoning**: Research â†’ Analysis â†’ Writing pipeline\n",
    "- **Scalable**: Easy to add new agents or modify workflow\n",
    "- **Observable**: Comprehensive logging and state tracking\n",
    "\n",
    "### Customization Options\n",
    "\n",
    "1. **Add Agents**: Create specialized agents (fact-checker, summarizer, etc.)\n",
    "2. **Custom Tools**: Integrate additional APIs or data sources\n",
    "3. **Routing Logic**: Implement more sophisticated agent routing\n",
    "4. **Memory**: Add conversation memory or long-term storage\n",
    "5. **Parallel Execution**: Run multiple agents concurrently\n",
    "\n",
    "### Environment Variables Required\n",
    "\n",
    "Create a `.env` file with:\n",
    "```\n",
    "GOOGLE_API_KEY=your_google_api_key\n",
    "GOOGLE_CSE_ID=your_custom_search_engine_id\n",
    "```\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Google ADK Documentation](https://ai.google.dev/)\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [Google Custom Search API](https://developers.google.com/custom-search/v1/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final demo\n",
    "print(\"Multi-Agent Workflow with Google ADK and Search Grounding\")\n",
    "print(\"Ready to process queries!\\n\")\n",
    "print(\"Example usage:\")\n",
    "print(\"  result = workflow.run('Your query here')\")\n",
    "print(\"  print(result['final_output'])\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
